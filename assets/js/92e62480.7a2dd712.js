"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([[8253],{28453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>l});var i=s(96540);const r={},t=i.createContext(r);function o(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(t.Provider,{value:n},e.children)}},42450:(e,n,s)=>{s.d(n,{A:()=>m});var i=s(96540),r=s(5556),t=s.n(r),o=s(34164);const l="collapsibleContent_q3kw",a="header_QCEw",d="icon_PckA",c="content_qLC1",h="expanded_iGsi";var u=s(74848);function p({children:e,header:n}){const[s,r]=(0,i.useState)(!1);return(0,u.jsxs)("div",{className:l,children:[(0,u.jsxs)("div",{className:(0,o.A)(a,{[h]:s}),onClick:()=>{r(!s)},children:[n,(0,u.jsx)("span",{className:(0,o.A)(d,{[h]:s}),children:s?"\ud83d\udc47":"\ud83d\udc48"})]}),s&&(0,u.jsx)("div",{className:c,children:e})]})}p.propTypes={children:t().node.isRequired,header:t().node.isRequired};const m=p},83431:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>u,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"blueprints/inference/GPUs/nvidia-dynamo","title":"NVIDIA Dynamo on Amazon EKS","description":"Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn\'t working, it\'s often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren\'t initializing, check the logs for Karpenter or Node groups to resolve the issue.","source":"@site/docs/blueprints/inference/GPUs/nvidia-dynamo.md","sourceDirName":"blueprints/inference/GPUs","slug":"/blueprints/inference/GPUs/nvidia-dynamo","permalink":"/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo","draft":false,"unlisted":false,"editUrl":"https://github.com/awslabs/ai-on-eks/blob/main/website/docs/blueprints/inference/GPUs/nvidia-dynamo.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"title":"NVIDIA Dynamo on Amazon EKS","sidebar_position":8},"sidebar":"blueprints","previous":{"title":"DeepSeek-R1 on EKS","permalink":"/ai-on-eks/docs/blueprints/inference/GPUs/ray-vllm-deepseek"},"next":{"title":"AIBrix on EKS","permalink":"/ai-on-eks/docs/blueprints/inference/GPUs/aibrix-deepseek-distill"}}');var r=s(74848),t=s(28453),o=s(42450);const l={title:"NVIDIA Dynamo on Amazon EKS",sidebar_position:8},a="NVIDIA Dynamo on Amazon EKS",d={},c=[{value:"Quick Start",id:"quick-start",level:2},{value:"What is NVIDIA Dynamo?",id:"what-is-nvidia-dynamo",level:2},{value:"What is an Inference Graph?",id:"what-is-an-inference-graph",level:3},{value:"Overview",id:"overview",level:2},{value:"Deployment Approach",id:"deployment-approach",level:3},{value:"Key Features",id:"key-features",level:3},{value:"Architecture",id:"architecture",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Step 1: Clone the Repository",id:"step-1-clone-the-repository",level:3},{value:"Step 2: Deploy Infrastructure and Platform",id:"step-2-deploy-infrastructure-and-platform",level:3},{value:"Step 3: Build Base Images",id:"step-3-build-base-images",level:3},{value:"Step 4: Deploy Inference Graphs",id:"step-4-deploy-inference-graphs",level:3},{value:"Test and Validate",id:"test-and-validate",level:2},{value:"Automated Testing",id:"automated-testing",level:3},{value:"Manual Testing",id:"manual-testing",level:3},{value:"Monitor and Observe",id:"monitor-and-observe",level:2},{value:"Grafana Dashboard",id:"grafana-dashboard",level:3},{value:"Prometheus Metrics",id:"prometheus-metrics",level:3},{value:"Automatic Monitoring",id:"automatic-monitoring",level:3},{value:"Advanced Configuration",id:"advanced-configuration",level:2},{value:"ECR Authentication",id:"ecr-authentication",level:3},{value:"Custom Model Deployment",id:"custom-model-deployment",level:3},{value:"Karpenter Node Pools",id:"karpenter-node-pools",level:3},{value:"Configuration Options",id:"configuration-options",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"Debug Commands",id:"debug-commands",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Alternative Deployment Options",id:"alternative-deployment-options",level:2},{value:"For Existing EKS Clusters",id:"for-existing-eks-clusters",level:3},{value:"Why Use This Blueprint?",id:"why-use-this-blueprint",level:3},{value:"Repository Information",id:"repository-information",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Clean Up",id:"clean-up",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.admonition,{type:"warning",children:(0,r.jsx)(n.p,{children:"Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn't working, it's often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren't initializing, check the logs for Karpenter or Node groups to resolve the issue."})}),"\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsx)(n.p,{children:"NVIDIA Dynamo is a cloud-native platform for deploying and managing AI inference graphs at scale. This implementation provides complete infrastructure setup with enterprise-grade monitoring and scalability on Amazon EKS."})}),"\n",(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"nvidia-dynamo-on-amazon-eks",children:"NVIDIA Dynamo on Amazon EKS"})}),"\n",(0,r.jsxs)(n.admonition,{title:"Active Development",type:"warning",children:[(0,r.jsxs)(n.p,{children:["This NVIDIA Dynamo blueprint is currently in ",(0,r.jsx)(n.strong,{children:"active development"}),". We are continuously improving the user experience and functionality. Features, configurations, and deployment processes may change between releases as we iterate and enhance the implementation based on user feedback and best practices."]}),(0,r.jsx)(n.p,{children:"Please expect iterative improvements in upcoming releases. If you encounter any issues or have suggestions for improvements, please feel free to open an issue or contribute to the project."})]}),"\n",(0,r.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Want to get started immediately?"})," Here's the minimal command sequence:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# 1. Clone and navigate\ngit clone https://github.com/awslabs/ai-on-eks.git && cd ai-on-eks/infra/nvidia-dynamo\n\n# 2. Deploy everything (15-30 minutes)\n./install.sh\n\n# 3. Build base image and deploy inference\ncd ../../blueprints/inference/nvidia-dynamo\nsource dynamo_env.sh\n./build-base-image.sh vllm --push\n./deploy.sh\n\n# 4. Test your deployment\n./test.sh\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Prerequisites"}),": AWS CLI, kubectl, docker, terraform, earthly, python3.10+, git (",(0,r.jsx)(n.a,{href:"#prerequisites",children:"detailed setup below"}),")"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"what-is-nvidia-dynamo",children:"What is NVIDIA Dynamo?"}),"\n",(0,r.jsx)(n.p,{children:"NVIDIA Dynamo is an open-source inference framework designed to optimize performance and scalability for large language models (LLMs) and generative AI applications."}),"\n",(0,r.jsx)(n.h3,{id:"what-is-an-inference-graph",children:"What is an Inference Graph?"}),"\n",(0,r.jsxs)(n.p,{children:["An ",(0,r.jsx)(n.strong,{children:"inference graph"})," is a computational workflow that defines how AI models process data through interconnected nodes, enabling complex multi-step AI operations like:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LLM chains"}),": Sequential processing through multiple language models"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multimodal processing"}),": Combining text, image, and audio processing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Custom inference pipelines"}),": Tailored workflows for specific AI applications"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Disaggregated serving"}),": Separating prefill and decode phases for optimal resource utilization"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsxs)(n.p,{children:["This blueprint uses the ",(0,r.jsx)(n.strong,{children:"official NVIDIA Dynamo Helm charts"})," from the dynamo source repository, with additional shell scripts and Terraform automation to simplify the deployment process on Amazon EKS."]}),"\n",(0,r.jsx)(n.h3,{id:"deployment-approach",children:"Deployment Approach"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Why This Setup Process?"}),"\nWhile this implementation involves multiple steps, it provides several advantages over a simple Helm-only deployment:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Complete Infrastructure"}),": Automatically provisions VPC, EKS cluster, ECR repositories, and monitoring stack"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Production Ready"}),": Includes enterprise-grade security, monitoring, and scalability features"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"AWS Integration"}),": Leverages EKS autoscaling, EFA networking, and AWS services"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Customizable"}),": Allows fine-tuning of GPU node pools, networking, and resource allocation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reproducible"}),": Infrastructure as Code ensures consistent deployments across environments"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"For Simpler Deployments"}),": If you already have an EKS cluster and prefer a minimal setup, you can use the Dynamo Helm charts directly from the source repository. This blueprint provides the full production-ready experience."]}),"\n",(0,r.jsx)(n.p,{children:"As LLMs and generative AI applications become increasingly prevalent, the demand for efficient, scalable, and low-latency inference solutions has grown. Traditional inference systems often struggle to meet these demands, especially in distributed, multi-node environments. NVIDIA Dynamo addresses these challenges by offering innovative solutions to optimize performance and scalability with support for AWS services such as Amazon S3, Elastic Fabric Adapter (EFA), and Amazon EKS."}),"\n",(0,r.jsx)(n.h3,{id:"key-features",children:"Key Features"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Performance Optimizations:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Disaggregated Serving"}),": Separates prefill and decode phases across different GPUs for optimal resource utilization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamic GPU Scheduling"}),": Intelligent resource allocation based on real-time demand through the NVIDIA Dynamo Planner"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Smart Request Routing"}),": Minimizes KV cache recomputation by routing requests to workers with relevant cached data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Accelerated Data Transfer"}),": Low-latency communication via NVIDIA NIXL library"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Efficient KV Cache Management"}),": Intelligent offloading across memory hierarchies with the KV Cache Block Manager"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Infrastructure Ready:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Inference Engine Agnostic"}),": Supports TensorRT-LLM, vLLM, SGLang, and other runtimes"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Modular Design"}),": Pick and choose components that fit your existing AI stack"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Enterprise Grade"}),": Complete monitoring, logging, and security integration"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Amazon EKS Optimized"}),": Leverages EKS autoscaling, GPU support, and AWS services"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,r.jsx)(n.p,{children:"The deployment uses Amazon EKS with the following components:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://github.com/ai-dynamo/dynamo/blob/main/docs/images/architecture.png?raw=true",alt:"NVIDIA Dynamo Architecture"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Key Components:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"VPC and Networking"}),": Standard VPC with EFA support for low-latency inter-node communication"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"EKS Cluster"}),": Managed Kubernetes with GPU-enabled node groups using Karpenter"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamo Platform"}),": Operator, API Store, and supporting services (NATS, PostgreSQL, MinIO)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Monitoring Stack"}),": Prometheus, Grafana, and AI/ML observability"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Storage"}),": Amazon EFS for shared model storage and caching"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"System Requirements"}),": Ubuntu 22.04 or 24.04 (NVIDIA Dynamo officially supports only these versions)"]}),"\n",(0,r.jsx)(n.p,{children:"Install the following tools on your setup host (recommended: EC2 instance t3.xlarge or higher with EKS and ECR permissions):"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"AWS CLI"}),": Configured with appropriate permissions (",(0,r.jsx)(n.a,{href:"https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html",children:"installation guide"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"kubectl"}),": Kubernetes command-line tool (",(0,r.jsx)(n.a,{href:"https://kubernetes.io/docs/tasks/tools/install-kubectl/",children:"installation guide"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"helm"}),": Kubernetes package manager (",(0,r.jsx)(n.a,{href:"https://helm.sh/docs/intro/install/",children:"installation guide"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"terraform"}),": Infrastructure as code tool (",(0,r.jsx)(n.a,{href:"https://learn.hashicorp.com/tutorials/terraform/install-cli",children:"installation guide"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"docker"}),": With buildx and user needs docker permissions (",(0,r.jsx)(n.a,{href:"https://docs.docker.com/get-docker/",children:"installation guide"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"earthly"}),": Multi-platform build automation tool used by NVIDIA Dynamo for reproducible container builds (",(0,r.jsx)(n.a,{href:"https://earthly.dev/get-earthly",children:"installation guide"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Python 3.10+"}),": With pip and venv (",(0,r.jsx)(n.a,{href:"https://www.python.org/downloads/",children:"installation guide"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"git"}),": Version control (",(0,r.jsx)(n.a,{href:"https://git-scm.com/book/en/v2/Getting-Started-Installing-Git",children:"installation guide"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"EKS Cluster"}),": Version 1.33 (tested and supported)"]}),"\n"]}),"\n",(0,r.jsxs)(o.A,{header:(0,r.jsx)(n.h2,{children:(0,r.jsx)(n.span,{children:"Deploying the Solution"})}),children:[(0,r.jsx)(n.p,{children:"Complete the following steps to deploy NVIDIA Dynamo on Amazon EKS:"}),(0,r.jsx)(n.h3,{id:"step-1-clone-the-repository",children:"Step 1: Clone the Repository"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/awslabs/ai-on-eks.git && cd ai-on-eks\n"})}),(0,r.jsx)(n.h3,{id:"step-2-deploy-infrastructure-and-platform",children:"Step 2: Deploy Infrastructure and Platform"}),(0,r.jsx)(n.p,{children:"Navigate to the infrastructure directory and run the installation script:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd infra/nvidia-dynamo\n./install.sh\n"})}),(0,r.jsx)(n.p,{children:"This command provisions your complete environment:"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"VPC"}),": Subnets, security groups, NAT gateways, and internet gateway"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"EKS Cluster"}),": With GPU-enabled node groups using Karpenter"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ECR Repositories"}),": For Dynamo container images"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Monitoring Stack"}),": Prometheus, Grafana, and AI/ML observability"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamo Platform"}),": Deploys using official NVIDIA Dynamo Helm charts (Operator, API Store, NATS, PostgreSQL, MinIO)"]}),"\n"]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Duration"}),": 15-30 minutes"]}),(0,r.jsx)(n.h3,{id:"step-3-build-base-images",children:"Step 3: Build Base Images"}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Why Custom Image Builds?"}),"\nCurrently, official NVIDIA Dynamo container images are not yet available from NVIDIA's public registries. This blueprint builds the required images using the official Dynamo build process and pushes them to your private ECR repositories. Future releases will include pre-built images from NVIDIA."]}),(0,r.jsx)(n.p,{children:"Build and push the base images for your chosen inference framework:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd blueprints/inference/nvidia-dynamo\nsource dynamo_env.sh   # Generated by install.sh with AWS credentials\n\n# Build vLLM base image (recommended for most LLMs)\n./build-base-image.sh vllm --push\n\n# Optional: Build other framework images\n./build-base-image.sh tensorrtllm --push\n./build-base-image.sh sglang --push\n"})}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Framework Options:"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"vLLM"}),": Best for most LLMs, supports many model formats"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TensorRT-LLM"}),": Optimized for NVIDIA GPUs, fastest inference"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SGLang"}),": Structured generation for complex prompting"]}),"\n"]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Build Process:"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Uses the official Dynamo ",(0,r.jsx)(n.code,{children:"container/build.sh"})," script"]}),"\n",(0,r.jsx)(n.li,{children:"Leverages Earthly for reproducible, multi-platform builds"}),"\n",(0,r.jsx)(n.li,{children:"Configures CUDA drivers and framework-specific dependencies"}),"\n",(0,r.jsx)(n.li,{children:"Pushes to your private ECR repositories for secure access"}),"\n"]}),(0,r.jsx)(n.h3,{id:"step-4-deploy-inference-graphs",children:"Step 4: Deploy Inference Graphs"}),(0,r.jsx)(n.p,{children:"Deploy your inference service using the interactive deployment script:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"./deploy.sh\n"})}),(0,r.jsx)(n.p,{children:"The interactive menu will guide you through:"}),(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Example Type"}),": Choose between hello-world or llm"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LLM Architecture"}),": Select from agg, disagg, agg_router, disagg_router, multinode options"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Automatic Configuration"}),": Sets up monitoring and service exposure"]}),"\n"]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Architecture Options:"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"agg"}),": Aggregated - single node processing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"disagg"}),": Disaggregated - separate prefill/decode phases"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"agg_router"}),": Aggregated with smart routing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"disagg_router"}),": Disaggregated with smart routing (recommended)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"multinode"}),": Multi-node setups for large models"]}),"\n"]}),(0,r.jsx)(n.p,{children:"The deployment creates monitoring resources (Service and ServiceMonitor) automatically."})]}),"\n",(0,r.jsx)(n.h2,{id:"test-and-validate",children:"Test and Validate"}),"\n",(0,r.jsx)(n.h3,{id:"automated-testing",children:"Automated Testing"}),"\n",(0,r.jsx)(n.p,{children:"Use the built-in test script to validate your deployment:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"./test.sh\n"})}),"\n",(0,r.jsx)(n.p,{children:"This script:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Starts port forwarding to the frontend service"}),"\n",(0,r.jsxs)(n.li,{children:["Tests health check, metrics, and ",(0,r.jsx)(n.code,{children:"/v1/models"})," endpoints"]}),"\n",(0,r.jsx)(n.li,{children:"Runs sample inference requests to verify functionality"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"manual-testing",children:"Manual Testing"}),"\n",(0,r.jsx)(n.p,{children:"Access your deployment directly:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'kubectl port-forward svc/<frontend-service> 3000:3000 -n dynamo-cloud &\n\ncurl -X POST http://localhost:3000/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",\n    "messages": [\n        {"role": "user", "content": "Explain what a Q-Bit is in quantum computing."}\n    ],\n    "max_tokens": 2000,\n    "temperature": 0.7,\n    "stream": false\n}\'\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Expected Output:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "id": "1918b11a-6d98-4891-bc84-08f99de70fd0",\n  "choices": [\n    {\n      "index": 0,\n      "message": {\n        "content": "A Q-bit, or qubit, is the basic unit of quantum information...",\n        "role": "assistant"\n      },\n      "finish_reason": "stop"\n    }\n  ],\n  "created": 1752018267,\n  "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",\n  "object": "chat.completion"\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"monitor-and-observe",children:"Monitor and Observe"}),"\n",(0,r.jsx)(n.h3,{id:"grafana-dashboard",children:"Grafana Dashboard"}),"\n",(0,r.jsx)(n.p,{children:"Access Grafana for visualization (default port 3000):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl port-forward -n kube-prometheus-stack svc/kube-prometheus-stack-grafana 3000:80\n"})}),"\n",(0,r.jsx)(n.h3,{id:"prometheus-metrics",children:"Prometheus Metrics"}),"\n",(0,r.jsx)(n.p,{children:"Access Prometheus for metrics collection (port 9090):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kubectl port-forward -n kube-prometheus-stack svc/prometheus 9090:80\n"})}),"\n",(0,r.jsx)(n.h3,{id:"automatic-monitoring",children:"Automatic Monitoring"}),"\n",(0,r.jsx)(n.p,{children:"The deployment automatically creates:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Service"}),": Exposes inference graphs for API calls and metrics"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ServiceMonitor"}),": Configures Prometheus to scrape metrics"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dashboards"}),": Pre-configured Grafana dashboards for inference monitoring"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"advanced-configuration",children:"Advanced Configuration"}),"\n",(0,r.jsx)(n.h3,{id:"ecr-authentication",children:"ECR Authentication"}),"\n",(0,r.jsxs)(n.p,{children:["The deployment uses ",(0,r.jsx)(n.strong,{children:"IRSA (IAM Roles for Service Accounts)"})," for secure ECR access:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Primary Method"}),": IRSA eliminates credential rotation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fallback Method"}),": ECR token refresh CronJob (legacy mode)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Security"}),": Service accounts automatically authenticate to ECR"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"No Secrets"}),": No long-lived credentials stored in Kubernetes"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Note"}),": AWS Pod Identity is available as an alternative to IRSA (GA since April 2024), but IRSA remains the recommended approach due to its maturity, wide adoption, and proven reliability in production environments."]}),"\n",(0,r.jsx)(n.h3,{id:"custom-model-deployment",children:"Custom Model Deployment"}),"\n",(0,r.jsxs)(n.p,{children:["To deploy custom models, modify the configuration files in ",(0,r.jsx)(n.code,{children:"dynamo/examples/llm/configs/"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Choose Architecture"}),": Select based on model size and requirements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Update Configuration"}),": Edit the appropriate YAML file"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Set Model Parameters"}),": Update ",(0,r.jsx)(n.code,{children:"model"})," and ",(0,r.jsx)(n.code,{children:"served_model_name"})," fields"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Configure Resources"}),": Adjust GPU allocation and memory settings"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example for DeepSeek-R1 70B model:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"Common:\n  model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B\n  max-model-len: 32768\n  tensor-parallel-size: 4\n\nFrontend:\n  served_model_name: deepseek-ai/DeepSeek-R1-Distill-Llama-70B\n\nVllmWorker:\n  ServiceArgs:\n    resources:\n      gpu: '4'\n"})}),"\n",(0,r.jsx)(n.h3,{id:"karpenter-node-pools",children:"Karpenter Node Pools"}),"\n",(0,r.jsx)(n.p,{children:"The deployment can optionally use custom Karpenter node pools optimized for NVIDIA Dynamo:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"C7i CPU Pools"}),": For general compute and BuildKit (newer than base M5 instances)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"G6 GPU Pools"}),": For inference workloads with NVIDIA L4 GPUs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Higher Priority"}),": Weight 100 vs base addons weight 50 for priority scheduling"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"BuildKit Support"}),": User namespace configuration for container builds"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"EFA Support"}),": Low-latency networking for multi-node setups"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Note"}),": Custom node pools are disabled by default. The base infrastructure provides existing Karpenter node pools (G6 GPU, G5 GPU, M5 CPU) that work well for most Dynamo workloads. Enable custom pools only if you need BuildKit support or higher scheduling priority."]}),"\n",(0,r.jsx)(n.h3,{id:"configuration-options",children:"Configuration Options"}),"\n",(0,r.jsxs)(n.p,{children:["Modify ",(0,r.jsx)(n.code,{children:"terraform/blueprint.tfvars"})," for customization:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-hcl",children:"# Enable custom node pools (optional - disabled by default)\nenable_custom_karpenter_nodepools = true\n\n# Choose AMI (AL2023 recommended)\nuse_bottlerocket = false\n\n# Resource limits\nkarpenter_cpu_limits = 10000\nkarpenter_memory_limits = 10000\n"})}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GPU Nodes Not Available"}),": Check Karpenter logs and instance availability"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Image Pull Errors"}),": Verify ECR repositories and image push success"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pod Failures"}),": Check resource limits and cluster capacity"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Deployment Timeouts"}),": Ensure base images are built and available"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"debug-commands",children:"Debug Commands"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Check cluster status\nkubectl get nodes\nkubectl get pods -n dynamo-cloud\n\n# View logs\nkubectl logs -n dynamo-cloud deployment/dynamo-operator\nkubectl logs -n dynamo-cloud deployment/dynamo-api-store\n\n# Check deployments\nsource dynamo_venv/bin/activate\ndynamo deployment list --endpoint "$DYNAMO_CLOUD"\n'})}),"\n",(0,r.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model Size Guidelines"}),": Use appropriate architecture for model parameters"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Resource Allocation"}),": Match GPU count to model requirements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Network Configuration"}),": Ensure EFA is enabled for multi-node setups"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Storage"}),": Use EFS for shared model storage and caching"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"alternative-deployment-options",children:"Alternative Deployment Options"}),"\n",(0,r.jsx)(n.h3,{id:"for-existing-eks-clusters",children:"For Existing EKS Clusters"}),"\n",(0,r.jsx)(n.p,{children:"If you already have an EKS cluster with GPU nodes and prefer a simpler approach:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Direct Helm Installation"}),": Use the official NVIDIA Dynamo Helm charts directly from the ",(0,r.jsx)(n.a,{href:"https://github.com/ai-dynamo/dynamo",children:"dynamo source repository"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Manual Setup"}),": Follow the upstream NVIDIA Dynamo documentation for Kubernetes deployment"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Custom Integration"}),": Integrate Dynamo components into your existing infrastructure"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"why-use-this-blueprint",children:"Why Use This Blueprint?"}),"\n",(0,r.jsx)(n.p,{children:"This blueprint is designed for users who want:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Complete Infrastructure"}),": End-to-end setup from VPC to running inference"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Production Readiness"}),": Enterprise-grade monitoring, security, and scalability"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"AWS Integration"}),": Optimized for EKS, ECR, EFA, and other AWS services"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Best Practices"}),": Follows ai-on-eks patterns and AWS recommendations"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"repository-information",children:"Repository Information"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Repository"}),": ",(0,r.jsx)(n.a,{href:"https://github.com/awslabs/ai-on-eks",children:"awslabs/ai-on-eks"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Documentation"}),": ",(0,r.jsx)(n.a,{href:"https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-dynamo",children:"Complete NVIDIA Dynamo Blueprint"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"NVIDIA Dynamo"}),": ",(0,r.jsx)(n.a,{href:"https://docs.nvidia.com/dynamo/",children:"Official Documentation"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamo Source"}),": ",(0,r.jsx)(n.a,{href:"https://github.com/ai-dynamo/dynamo",children:"NVIDIA Dynamo Repository"})]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Explore Examples"}),": Check the examples folder in the GitHub repository"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Scale Deployments"}),": Configure multi-node setups for larger models"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Integrate Applications"}),": Connect your applications to the inference endpoints"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Monitor Performance"}),": Use Grafana dashboards for ongoing monitoring"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Optimize Costs"}),": Implement auto-scaling and resource optimization"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"clean-up",children:"Clean Up"}),"\n",(0,r.jsx)(n.p,{children:"When you're finished with your NVIDIA Dynamo deployment, remove all resources using the cleanup script:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd infra/nvidia-dynamo\n./cleanup.sh\n"})}),"\n",(0,r.jsx)(n.p,{children:"This safely destroys the NVIDIA Dynamo deployments and infrastructure components in the correct order, including:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dynamo platform components and workloads"}),"\n",(0,r.jsx)(n.li,{children:"Kubernetes resources and namespaces"}),"\n",(0,r.jsx)(n.li,{children:"ECR repositories and container images"}),"\n",(0,r.jsx)(n.li,{children:"Terraform-managed infrastructure (EKS cluster, VPC, etc.)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The cleanup script ensures proper resource cleanup to avoid any lingering costs."}),"\n",(0,r.jsx)(n.p,{children:"This deployment provides a production-ready NVIDIA Dynamo environment on Amazon EKS with enterprise-grade features including Karpenter automatic scaling, EFA networking, and seamless AWS service integration."})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}}}]);