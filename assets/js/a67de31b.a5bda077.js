"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([[914],{28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var r=i(96540);const s={},t=r.createContext(s);function l(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),r.createElement(t.Provider,{value:n},e.children)}},70903:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"blueprints/inference/index","title":"Inference on EKS","description":"AI on EKS provides comprehensive solutions for deploying AI/ML inference workloads on Amazon EKS, supporting both GPU and AWS Neuron (Inferentia/Trainium) hardware configurations.","source":"@site/docs/blueprints/inference/index.md","sourceDirName":"blueprints/inference","slug":"/blueprints/inference/","permalink":"/ai-on-eks/docs/blueprints/inference/","draft":false,"unlisted":false,"editUrl":"https://github.com/awslabs/ai-on-eks/blob/main/website/docs/blueprints/inference/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Overview","sidebar_position":1},"sidebar":"blueprints","previous":{"title":"Ray Serve High Availability","permalink":"/ai-on-eks/docs/blueprints/inference/Neuron/rayserve-ha"},"next":{"title":"Inference Charts","permalink":"/ai-on-eks/docs/blueprints/inference/inference-charts"}}');var s=i(74848),t=i(28453);const l={sidebar_label:"Overview",sidebar_position:1},o="Inference on EKS",c={},d=[{value:"Quick Start Options",id:"quick-start-options",level:2},{value:"\ud83d\ude80 Inference Charts (Recommended)",id:"-inference-charts-recommended",level:3},{value:"Hardware-Specific Guides",id:"hardware-specific-guides",level:2},{value:"GPU Deployments",id:"gpu-deployments",level:3},{value:"Neuron Deployments (AWS Inferentia)",id:"neuron-deployments-aws-inferentia",level:3},{value:"Architecture Overview",id:"architecture-overview",level:2},{value:"Choosing the Right Approach",id:"choosing-the-right-approach",level:2},{value:"Next Steps",id:"next-steps",level:2}];function a(e){const n={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"inference-on-eks",children:"Inference on EKS"})}),"\n",(0,s.jsx)(n.p,{children:"AI on EKS provides comprehensive solutions for deploying AI/ML inference workloads on Amazon EKS, supporting both GPU and AWS Neuron (Inferentia/Trainium) hardware configurations."}),"\n",(0,s.jsx)(n.h2,{id:"quick-start-options",children:"Quick Start Options"}),"\n",(0,s.jsx)(n.h3,{id:"-inference-charts-recommended",children:"\ud83d\ude80 Inference Charts (Recommended)"}),"\n",(0,s.jsx)(n.p,{children:"Get started quickly with our pre-configured Helm charts that support multiple models and deployment patterns:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/inference-charts",children:"Inference Charts"})})," - Streamlined Helm-based deployments with pre-configured values for popular models"]}),"\n",(0,s.jsx)(n.li,{children:"Supports both GPU and Neuron hardware"}),"\n",(0,s.jsx)(n.li,{children:"Includes VLLM and Ray-VLLM frameworks"}),"\n",(0,s.jsx)(n.li,{children:"Pre-configured for 10+ popular models including Llama, DeepSeek, and Mistral"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"hardware-specific-guides",children:"Hardware-Specific Guides"}),"\n",(0,s.jsx)(n.h3,{id:"gpu-deployments",children:"GPU Deployments"}),"\n",(0,s.jsx)(n.p,{children:"Explore GPU-specific inference solutions:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/GPUs/ray-vllm-deepseek",children:"DeepSeek-R1 with Ray and vLLM"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-nim-llama3",children:"NVIDIA NIM with Llama3"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-nim-operator",children:"NVIDIA NIM Operator"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/GPUs/vLLM-NVIDIATritonServer",children:"vLLM with NVIDIA Triton Server"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/GPUs/vLLM-rayserve",children:"vLLM with Ray Serve"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/GPUs/stablediffusion-gpus",children:"Stable Diffusion on GPUs"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/GPUs/aibrix-deepseek-distill",children:"AIBrix with DeepSeek"})}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"neuron-deployments-aws-inferentia",children:"Neuron Deployments (AWS Inferentia)"}),"\n",(0,s.jsx)(n.p,{children:"Leverage AWS Inferentia chips for cost-effective inference:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/Neuron/llama2-inf2",children:"Llama2 on Inferentia2"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/Neuron/llama3-inf2",children:"Llama3 on Inferentia2"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/Neuron/Mistral-7b-inf2",children:"Mistral 7B on Inferentia2"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/Neuron/rayserve-ha",children:"Ray Serve High Availability"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/Neuron/vllm-ray-inf2",children:"vLLM with Ray on Inferentia2"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/Neuron/stablediffusion-inf2",children:"Stable Diffusion on Inferentia2"})}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"architecture-overview",children:"Architecture Overview"}),"\n",(0,s.jsx)(n.p,{children:"AI on EKS inference solutions support multiple deployment patterns:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Single-node inference"})," with vLLM"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Distributed inference"})," with Ray-vLLM"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Production-ready"})," deployments with load balancing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Auto-scaling"})," capabilities"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Observability"})," and monitoring integration"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"choosing-the-right-approach",children:"Choosing the Right Approach"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Use Case"}),(0,s.jsx)(n.th,{children:"Recommended Solution"}),(0,s.jsx)(n.th,{children:"Benefits"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Quick prototyping"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/inference-charts",children:"Inference Charts"})}),(0,s.jsx)(n.td,{children:"Pre-configured, fast deployment"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"GPU"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"/docs/category/gpu-inference-on-eks",children:"GPU-specific guides"})}),(0,s.jsx)(n.td,{children:"GPU-based inference"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Neuron"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"/docs/category/neuron-inference-on-eks",children:"Neuron guides"})}),(0,s.jsx)(n.td,{children:"Inferentia-based inference"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["Start with ",(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/blueprints/inference/inference-charts",children:"Inference Charts"})]})," for the fastest path to deployment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Explore hardware-specific guides"})," for optimized configurations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Set up monitoring and observability"})," for production workloads"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}}}]);