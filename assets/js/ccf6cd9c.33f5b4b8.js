"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([[324],{28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var s=i(96540);const a={},r=s.createContext(a);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(r.Provider,{value:n},e.children)}},42450:(e,n,i)=>{i.d(n,{A:()=>m});var s=i(96540),a=i(5556),r=i.n(a),t=i(34164);const l="collapsibleContent_q3kw",o="header_QCEw",d="icon_PckA",c="content_qLC1",u="expanded_iGsi";var h=i(74848);function p({children:e,header:n}){const[i,a]=(0,s.useState)(!1);return(0,h.jsxs)("div",{className:l,children:[(0,h.jsxs)("div",{className:(0,t.A)(o,{[u]:i}),onClick:()=>{a(!i)},children:[n,(0,h.jsx)("span",{className:(0,t.A)(d,{[u]:i}),children:i?"\ud83d\udc47":"\ud83d\udc48"})]}),i&&(0,h.jsx)("div",{className:c,children:e})]})}p.propTypes={children:r().node.isRequired,header:r().node.isRequired};const m=p},57021:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"blueprints/inference/GPUs/aibrix-deepseek-distill","title":"AIBrix","description":"AIBrix is an open source initiative designed to provide essential building blocks to construct scalable GenAI inference infrastructure. AIBrix delivers a cloud-native solution optimized for deploying, managing, and scaling large language model (LLM) inference, tailored specifically to enterprise needs.","source":"@site/docs/blueprints/inference/GPUs/aibrix-deepseek-distill.md","sourceDirName":"blueprints/inference/GPUs","slug":"/blueprints/inference/GPUs/aibrix-deepseek-distill","permalink":"/ai-on-eks/docs/blueprints/inference/GPUs/aibrix-deepseek-distill","draft":false,"unlisted":false,"editUrl":"https://github.com/awslabs/ai-on-eks/blob/main/website/docs/blueprints/inference/GPUs/aibrix-deepseek-distill.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"AIBrix on EKS"},"sidebar":"blueprints","previous":{"title":"NVIDIA Dynamo on Amazon EKS","permalink":"/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo"},"next":{"title":"Neuron Inference on EKS","permalink":"/ai-on-eks/docs/category/neuron-inference-on-eks"}}');var a=i(74848),r=i(28453),t=i(42450);const l={sidebar_label:"AIBrix on EKS"},o="AIBrix",d={},c=[{value:"Features",id:"features",level:3},{value:"Checking AIBrix Installation",id:"checking-aibrix-installation",level:3},{value:"Running a model on AiBrix system",id:"running-a-model-on-aibrix-system",level:4},{value:"Accessing the model using gateway",id:"accessing-the-model-using-gateway",level:4}];function u(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",pre:"pre",span:"span",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"aibrix",children:"AIBrix"})}),"\n",(0,a.jsxs)(n.p,{children:["AIBrix is an open source initiative designed to provide essential building blocks to construct scalable GenAI inference infrastructure. AIBrix delivers a cloud-native solution optimized for deploying, managing, and scaling large language model (LLM) inference, tailored specifically to enterprise needs.\n",(0,a.jsx)(n.img,{src:"https://aibrix.readthedocs.io/latest/_images/aibrix-architecture-v1.jpeg",alt:"Alt text"})]}),"\n",(0,a.jsx)(n.h3,{id:"features",children:"Features"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"LLM Gateway and Routing: Efficiently manage and direct traffic across multiple models and replicas."}),"\n",(0,a.jsx)(n.li,{children:"High-Density LoRA Management: Streamlined support for lightweight, low-rank adaptations of models."}),"\n",(0,a.jsx)(n.li,{children:"Distributed Inference: Scalable architecture to handle large workloads across multiple nodes."}),"\n",(0,a.jsx)(n.li,{children:"LLM App-Tailored Autoscaler: Dynamically scale inference resources based on real-time demand."}),"\n",(0,a.jsx)(n.li,{children:"Unified AI Runtime: A versatile sidecar enabling metric standardization, model downloading, and management."}),"\n",(0,a.jsx)(n.li,{children:"Heterogeneous-GPU Inference: Cost-effective SLO-driven LLM inference using heterogeneous GPUs."}),"\n",(0,a.jsx)(n.li,{children:"GPU Hardware Failure Detection: Proactive detection of GPU hardware issues."}),"\n"]}),"\n",(0,a.jsxs)(t.A,{header:(0,a.jsx)(n.h2,{children:(0,a.jsx)(n.span,{children:"Deploying the Solution"})}),children:[(0,a.jsx)(n.admonition,{type:"warning",children:(0,a.jsx)(n.p,{children:"Before deploying this blueprint, it is important to be cognizant of the costs associated with the utilization of GPU Instances."})}),(0,a.jsxs)(n.p,{children:["Please refer to ",(0,a.jsx)(n.a,{href:"https://awslabs.github.io/ai-on-eks/docs/infra/ai-ml/aibrix",children:"AI"})," page for deploying AIBrix models on EKS."]})]}),"\n",(0,a.jsx)(n.h3,{id:"checking-aibrix-installation",children:"Checking AIBrix Installation"}),"\n",(0,a.jsx)(n.p,{children:"Please run the below commands to check the AIBrix installation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"kubectl get pods -n aibrix-system\n"})}),"\n",(0,a.jsx)(n.p,{children:"Wait till all the pods are in Running status."}),"\n",(0,a.jsx)(n.h4,{id:"running-a-model-on-aibrix-system",children:"Running a model on AiBrix system"}),"\n",(0,a.jsx)(n.p,{children:"We will now run Deepseek-Distill-llama-8b model using AIBrix on EKS."}),"\n",(0,a.jsx)(n.p,{children:"Please run the below command."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"kubectl apply -f blueprints/inference/aibrix/deepseek-distill.yaml\n"})}),"\n",(0,a.jsx)(n.p,{children:"This will deploy the model on deepseek-aibrix namespace. Wait for few minutes and run"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"kubectl get pods -n deepseek-aibrix\n"})}),"\n",(0,a.jsx)(n.p,{children:"Wait for the pod to be in running state."}),"\n",(0,a.jsx)(n.h4,{id:"accessing-the-model-using-gateway",children:"Accessing the model using gateway"}),"\n",(0,a.jsx)(n.p,{children:"Gateway is designed to serve LLM requests and provides features such as dynamic model & LoRA adapter discovery, user configuration for request count & token usage budgeting, streaming and advanced routing strategies such as prefix-cache aware, heterogeneous GPU hardware.\nTo access the model using Gateway, Please run the below command"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"kubectl -n envoy-gateway-system port-forward service/envoy-aibrix-system-aibrix-eg-903790dc 8888:80 &\n"})}),"\n",(0,a.jsx)(n.p,{children:"Once the port-forward is running, you can test the model by sending a request to the Gateway."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'ENDPOINT="localhost:8888"\ncurl -v http://${ENDPOINT}/v1/completions \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n        "model": "deepseek-r1-distill-llama-8b",\n        "prompt": "San Francisco is a",\n        "max_tokens": 128,\n        "temperature": 0\n    }\'\n'})}),"\n",(0,a.jsxs)(t.A,{header:(0,a.jsx)(n.h2,{children:(0,a.jsx)(n.span,{children:"Cleanup"})}),children:[(0,a.jsxs)(n.p,{children:["This script will cleanup the environment using ",(0,a.jsx)(n.code,{children:"-target"})," option to ensure all the resources are deleted in correct order."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"kubectl delete -f blueprints/inference/aibrix/deepseek-distill.yaml\n"})}),(0,a.jsx)(n.p,{children:"To cleanup the AIBrix deployment, and delete the EKs cluster please run the below command"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"cd infra/aibrix/terraform\n./cleanup.sh\n"})})]}),"\n",(0,a.jsx)(n.admonition,{type:"caution",children:(0,a.jsx)(n.p,{children:"To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}}}]);