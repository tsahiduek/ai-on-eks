# ConfigMap containing Python scripts for timeslicing pods
apiVersion: v1
kind: ConfigMap
metadata:
  name: timeslicing-scripts-configmap
  namespace: timeslicing-gpu
data:
  inference-script.py: |
    import torch
    import time
    import os
    print(f"=== POD 1 STARTING ===")
    print(f"GPU available: {torch.cuda.is_available()}")
    print(f"GPU count: {torch.cuda.device_count()}")
    if torch.cuda.is_available():
        device = torch.cuda.current_device()
        print(f"Current GPU: {torch.cuda.get_device_name(device)}")
        print(f"GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB")
        # Simulate inference workload
        for i in range(20):
            x = torch.randn(1000, 1000).cuda()
            y = torch.mm(x, x.t())
            print(f"Pod 1 - Iteration {i+1} completed at {time.strftime('%H:%M:%S')}")
            time.sleep(5)
    else:
        print("No GPU available!")
        time.sleep(60)

  training-script.py: |
    import torch
    import time
    import os
    print(f"=== POD 2 STARTING ===")
    print(f"GPU available: {torch.cuda.is_available()}")
    print(f"GPU count: {torch.cuda.device_count()}")
    if torch.cuda.is_available():
        device = torch.cuda.current_device()
        print(f"Current GPU: {torch.cuda.get_device_name(device)}")
        print(f"GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB")
        # Simulate training workload with heavier compute
        for i in range(15):
            x = torch.randn(2000, 2000).cuda()
            y = torch.mm(x, x.t())
            loss = torch.sum(y)
            print(f"Pod 2 - Training step {i+1}, Loss: {loss.item():.2f} at {time.strftime('%H:%M:%S')}")
            time.sleep(5)
    else:
        print("No GPU available!")
        time.sleep(60)
---
# Pod 1 - Inference workload
apiVersion: v1
kind: Pod
metadata:
  name: inference-pod-1
  namespace: timeslicing-gpu
  labels:
    app: gpu-inference
spec:
  restartPolicy: Never
  containers:
  - name: inference-container
    image: nvcr.io/nvidia/pytorch:25.04-py3
    command: ["python", "/scripts/inference-script.py"]
    volumeMounts:
    - name: script-volume
      mountPath: /scripts
      readOnly: true
    resources:
      claims:
      - name: shared-gpu-claim
  resourceClaims:
  - name: shared-gpu-claim
    resourceClaimTemplateName: timeslicing-gpu-template
  nodeSelector:
    NodeGroupType: g6-mng
    nvidia.com/gpu.present: "true"
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
  volumes:
  - name: script-volume
    configMap:
      name: timeslicing-scripts-configmap
      defaultMode: 0755
---
# Pod 2 - Training workload
apiVersion: v1
kind: Pod
metadata:
  name: training-pod-2
  namespace: timeslicing-gpu
  labels:
    app: gpu-training
spec:
  restartPolicy: Never
  containers:
  - name: training-container
    image: nvcr.io/nvidia/pytorch:25.04-py3
    command: ["python", "/scripts/training-script.py"]
    volumeMounts:
    - name: script-volume
      mountPath: /scripts
      readOnly: true
    resources:
      claims:
      - name: shared-gpu-claim-2
  resourceClaims:
  - name: shared-gpu-claim-2
    resourceClaimTemplateName: timeslicing-gpu-template
  nodeSelector:
    NodeGroupType: g6-mng
    nvidia.com/gpu.present: "true"
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
  volumes:
  - name: script-volume
    configMap:
      name: timeslicing-scripts-configmap
      defaultMode: 0755
