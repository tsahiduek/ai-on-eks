<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-resources/dynamic-resource-allocation" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Dynamic Resource Allocation for GPUs on Amazon EKS | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/docs/resources/dynamic-resource-allocation"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Dynamic Resource Allocation for GPUs on Amazon EKS | AI on EKS"><meta data-rh="true" name="description" content="üöÄ TL;DR ‚Äì Dynamic GPU Scheduling with DRA on EKS"><meta data-rh="true" property="og:description" content="üöÄ TL;DR ‚Äì Dynamic GPU Scheduling with DRA on EKS"><link data-rh="true" rel="icon" href="/ai-on-eks/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/docs/resources/dynamic-resource-allocation"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/resources/dynamic-resource-allocation" hreflang="en"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/resources/dynamic-resource-allocation" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Dynamic Resource Allocation on EKS","item":"https://awslabs.github.io/ai-on-eks/docs/resources/dynamic-resource-allocation"}]}</script><link rel="stylesheet" href="/ai-on-eks/assets/css/styles.f2fe9425.css">
<script src="/ai-on-eks/assets/js/runtime~main.f57b42bc.js" defer="defer"></script>
<script src="/ai-on-eks/assets/js/main.107191fd.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/"><div class="navbar__logo"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/infra/ai-ml">Infrastructure</a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/blueprints">Blueprints</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/docs/resources/intro">Resources</a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/guidance">Guidance</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/resources/intro">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/resources/eks-best-practices">EKS Best Practices</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/resources/mountpoint-s3">Mounpoint-S3 on EKS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/resources/networking">Networking for AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/resources/binpacking-custom-scheduler-eks">Bin packing for Amazon EKS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/ai-on-eks/docs/resources/dynamic-resource-allocation">Dynamic Resource Allocation on EKS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/resources/observability">Observability</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai-on-eks/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Dynamic Resource Allocation on EKS</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Dynamic Resource Allocation for GPUs on Amazon EKS</h1></header>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><strong>üöÄ TL;DR ‚Äì Dynamic GPU Scheduling with DRA on EKS</strong></summary><div><div class="collapsibleContent_i85q"><p><strong>DRA is the next-generation GPU scheduling approach in Kubernetes.</strong> Dynamic Resource Allocation (DRA) provides advanced GPU management capabilities beyond traditional device plugins. Here&#x27;s what matters:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dra-advantages-over-traditional-gpu-scheduling">DRA Advantages over Traditional GPU Scheduling<a href="#dra-advantages-over-traditional-gpu-scheduling" class="hash-link" aria-label="Direct link to DRA Advantages over Traditional GPU Scheduling" title="Direct link to DRA Advantages over Traditional GPU Scheduling">‚Äã</a></h3><ul>
<li><strong>üéØ Fine-grained resource control</strong> ‚Äì Request specific GPU memory amounts, not just whole devices</li>
<li><strong>üîÑ Per-workload sharing strategies</strong> ‚Äì Choose <code>mps</code>, <code>time-slicing</code>, <code>mig</code>, or <code>exclusive</code> per pod, not cluster-wide</li>
<li><strong>üß† Topology-aware scheduling</strong> ‚Äì Understands <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a>, <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a>, and GPU interconnects for multi-GPU workloads</li>
<li><strong>‚ö° Advanced GPU features</strong> ‚Äì Required for <a href="https://aws.amazon.com/ec2/instance-types/p6/" target="_blank" rel="noopener noreferrer">Amazon EC2 P6e-GB200 UltraServers</a> <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a>, Multi-Node <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a>, and next-gen GPU capabilities</li>
<li><strong>ü§ù Coexistence-friendly</strong> ‚Äì Can run alongside traditional device plugins during transition</li>
</ul><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Amazon EC2 P6e-GB200 UltraServer Requirement</div><div class="admonitionContent_BuS1"><ul>
<li><strong>Traditional scheduling unsupported</strong> ‚Äì Amazon EC2 P6e-GB200 UltraServers <strong>require DRA</strong> and won&#x27;t work with NVIDIA device plugin + kube-scheduler</li>
<li><strong>DRA mandatory</strong> ‚Äì Multi-Node <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> and <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a> capabilities only available through DRA</li>
</ul></div></div><p><strong>Key Implementation Details:</strong></p><div class="statusGrid_yukc"><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">‚ò∏Ô∏è</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">EKS Control Plane</div><div class="badgeValue_YSlu">v1.33+</div><div class="badgeNote_j_gI">DRA feature gates enabled</div></div></div><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">üñ•Ô∏è</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">EKS Optimized NVIDIA AMI</div><div class="badgeValue_YSlu">Latest AMI</div><div class="badgeNote_j_gI">Pre-installed drivers</div></div></div><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">üîó</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">Managed Node Groups</div><div class="badgeValue_YSlu">Full DRA Support</div><div class="badgeNote_j_gI">Recommended approach</div></div></div><div class="statusBadge_vHeB statusBadgeInfo_l0Xz"><span class="badgeIcon_t9jD">üîß</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">Self-Managed Nodegroups</div><div class="badgeValue_YSlu">DRA Support</div><div class="badgeNote_j_gI">Manual configuration</div></div></div><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">üõ†Ô∏è</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">NVIDIA GPU Operator</div><div class="badgeValue_YSlu">v25.3.0+</div><div class="badgeNote_j_gI">Required for DRA</div></div></div><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">‚ö°</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">NVIDIA DRA Driver</div><div class="badgeValue_YSlu">v25.3.0+</div><div class="badgeNote_j_gI">Core DRA functionality</div></div></div><div class="statusBadge_vHeB statusBadgeWarning_NMyw"><span class="badgeIcon_t9jD">üöß</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">Karpenter DRA Support</div><div class="badgeValue_YSlu">In Development</div><div class="badgeNote_j_gI">GitHub Issue #1231</div></div></div><div class="statusBadge_vHeB statusBadgeBeta_HeJs"><span class="badgeIcon_t9jD">üî¨</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">DRA Status</div><div class="badgeValue_YSlu">Beta (K8s v1.32+)</div><div class="badgeNote_j_gI">Technology Preview</div></div></div></div><ul>
<li><strong>EKS v1.33</strong> ‚Äì DRA feature gates enabled in EKS-optimized configurations</li>
<li><strong>For detailed DRA implementation</strong> ‚Äì See <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/" target="_blank" rel="noopener noreferrer">Kubernetes DRA documentation</a></li>
<li><strong>Node provisioning compatibility:</strong>
<ul>
<li><strong>Managed Node Groups</strong> ‚Äì Full DRA support üéØ</li>
<li><strong>Self-Managed Node Groups</strong> ‚Äì DRA support (requires manual configuration) üîß</li>
<li><strong>Karpenter</strong> ‚Äì DRA support in development (<a href="https://github.com/kubernetes-sigs/karpenter/issues/1231" target="_blank" rel="noopener noreferrer">Issue #1231</a>) üèóÔ∏è</li>
</ul>
</li>
<li><strong>Coexistence</strong> ‚Äì Traditional device plugin and DRA can run simultaneously</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-managedself-managed-node-groups-vs-karpenter-for-dra">Why Managed/Self-Managed Node Groups vs Karpenter for DRA?<a href="#why-managedself-managed-node-groups-vs-karpenter-for-dra" class="hash-link" aria-label="Direct link to Why Managed/Self-Managed Node Groups vs Karpenter for DRA?" title="Direct link to Why Managed/Self-Managed Node Groups vs Karpenter for DRA?">‚Äã</a></h3><ul>
<li><strong>Managed/Self-Managed Node Groups</strong> ‚Äì Full DRA support, optimized for Capacity Block Reservations</li>
<li><strong>Karpenter</strong> ‚Äì DRA support in development, dynamic scaling conflicts with reserved GPU capacity</li>
<li><strong>EKS-optimized AMIs</strong> ‚Äì Come with pre-installed NVIDIA drivers</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="can-i-use-both-traditional-gpu-allocation-and-dra-together">Can I Use Both Traditional GPU Allocation and DRA Together?<a href="#can-i-use-both-traditional-gpu-allocation-and-dra-together" class="hash-link" aria-label="Direct link to Can I Use Both Traditional GPU Allocation and DRA Together?" title="Direct link to Can I Use Both Traditional GPU Allocation and DRA Together?">‚Äã</a></h3><ul>
<li><strong>Coexistence supported</strong> ‚Äì Both can run simultaneously on the same cluster</li>
<li><strong>DRA is the future</strong> ‚Äì NVIDIA and Kubernetes moving exclusively to DRA</li>
<li><strong>Migration strategy</strong> ‚Äì Use DRA for new workloads, traditional for existing production</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="production-readiness">Production Readiness<a href="#production-readiness" class="hash-link" aria-label="Direct link to Production Readiness" title="Direct link to Production Readiness">‚Äã</a></h3><ul>
<li><strong>Technology Preview</strong> ‚Äì GPU allocation and sharing features actively developed by NVIDIA</li>
<li><strong>Production Ready</strong> ‚Äì ComputeDomains for Multi-Node <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> fully supported</li>
<li><strong>Scheduling overhead</strong> ‚Äì Additional latency due to claim resolution process</li>
<li><strong>General Availability</strong> ‚Äì Expected in Kubernetes v1.34 (2025)</li>
<li><strong>Latest status updates</strong> ‚Äì Follow <a href="https://github.com/NVIDIA/k8s-dra-driver-gpu" target="_blank" rel="noopener noreferrer">NVIDIA DRA Driver GitHub</a> for current development progress</li>
</ul><div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Additional Resources</div><div class="admonitionContent_BuS1"><p>For comprehensive guidance on AI/ML workloads on EKS, see the <a href="https://docs.aws.amazon.com/eks/latest/best-practices/aiml-compute.html#aiml-dra" target="_blank" rel="noopener noreferrer">AWS EKS Best Practices for AI/ML Compute</a>.</p></div></div></div></div></details>
<div class="callout_FLm9 calloutCritical_bQ1o"><div class="calloutHeader_B5_v"><span class="calloutIcon_GXtC">üí∏</span><h4>Enterprise GPU Utilization Crisis</h4></div><div class="calloutContent_aVah"><div class="statHighlight_FjI5"><span class="statNumber_ZY16">60%</span><span class="statLabel_TIh8">GPU capacity wasted</span></div><p>Despite high demand, enterprise AI platforms consistently waste over half their GPU resources due to scheduling limitations. This represents millions in infrastructure costs.</p></div></div>
<p><strong>Even in high-demand AI clusters, GPU utilization frequently remains below 40%.</strong> This isn&#x27;t a configuration issue ‚Äî it&#x27;s a fundamental limitation of how Kubernetes abstracts GPU resources. Organizations are paying premium prices for GPU instances while letting the majority of compute power sit idle.</p>
<div class="sectionDivider_z07Q"><div class="dividerLine_oAnl"></div><div class="dividerIcon_Soi9">üéõÔ∏è</div><div class="dividerLine_oAnl"></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-gpu-scheduling-challenge-in-kubernetes">The GPU Scheduling Challenge in Kubernetes<a href="#the-gpu-scheduling-challenge-in-kubernetes" class="hash-link" aria-label="Direct link to The GPU Scheduling Challenge in Kubernetes" title="Direct link to The GPU Scheduling Challenge in Kubernetes">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="current-state-traditional-gpu-allocation">Current State: Traditional GPU Allocation<a href="#current-state-traditional-gpu-allocation" class="hash-link" aria-label="Direct link to Current State: Traditional GPU Allocation" title="Direct link to Current State: Traditional GPU Allocation">‚Äã</a></h3>
<p>Kubernetes has rapidly evolved into the de facto standard for orchestrating AI/ML workloads across enterprise environments, with Amazon EKS emerging as the leading platform for managing GPU-accelerated infrastructure at scale. Organizations are running everything from small inference services to massive distributed training jobs on EKS clusters, leveraging GPU instances like P4d, P5, and the latest P6 series to power their machine learning pipelines.</p>
<p>However, despite Kubernetes&#x27; sophistication in managing containerized workloads, the traditional GPU scheduling model remains surprisingly primitive and creates significant operational challenges. The current approach treats GPUs as simple, atomic resources that can only be allocated in whole units, fundamentally mismatched with the diverse and evolving needs of modern AI workloads.</p>
<p><strong>How Traditional GPU Scheduling Works:</strong></p>
<ul>
<li>Pods request GPUs using simple integer values: <code>nvidia.com/gpu: 1</code></li>
<li>Scheduler treats GPUs as opaque, indivisible resources</li>
<li>Each workload gets exclusive access to entire GPU devices</li>
<li>No awareness of actual resource requirements or GPU topology</li>
</ul>
<p><strong>The Problem with This Approach:</strong>
Modern AI workloads have diverse requirements that don&#x27;t fit this binary model:</p>
<ul>
<li><strong>Small inference jobs</strong> need only 2-4GB GPU memory but get allocated entire 80GB A100s</li>
<li><strong>Large training jobs</strong> require coordinated multi-GPU communication via <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> or <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a></li>
<li><strong>Mixed workloads</strong> could share GPUs efficiently but are forced into separate devices</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-gpu-utilization-crisis">The GPU Utilization Crisis<a href="#the-gpu-utilization-crisis" class="hash-link" aria-label="Direct link to The GPU Utilization Crisis" title="Direct link to The GPU Utilization Crisis">‚Äã</a></h3>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Critical Inefficiency in Production</div><div class="admonitionContent_BuS1"><p><strong>Even in high-demand clusters, GPU utilization frequently remains below 40%.</strong> This isn&#x27;t a configuration issue: it&#x27;s a fundamental limitation of how Kubernetes abstracts GPU resources.</p></div></div>
<p><strong>Common symptoms of inefficient GPU allocation:</strong></p>
<ul>
<li><strong>Queue starvation</strong> - Small inference jobs wait behind long-running training tasks</li>
<li><strong>Resource fragmentation</strong> - GPU memory is stranded in unusable chunks across nodes</li>
<li><strong>Topology blindness</strong> - Multi-GPU jobs get suboptimal placement, degrading <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> performance</li>
<li><strong>Cost explosion</strong> - Organizations overprovision GPUs to work around scheduling inefficiencies</li>
</ul>
<div class="sectionDivider_z07Q"><div class="dividerLine_oAnl"></div><div class="dividerIcon_Soi9">üíé</div><div class="dividerLine_oAnl"></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="enter-dynamic-resource-allocation-dra">Enter Dynamic Resource Allocation (DRA)<a href="#enter-dynamic-resource-allocation-dra" class="hash-link" aria-label="Direct link to Enter Dynamic Resource Allocation (DRA)" title="Direct link to Enter Dynamic Resource Allocation (DRA)">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-dra-changes">What DRA Changes<a href="#what-dra-changes" class="hash-link" aria-label="Direct link to What DRA Changes" title="Direct link to What DRA Changes">‚Äã</a></h3>
<p>Dynamic Resource Allocation fundamentally transforms GPU scheduling in Kubernetes from a rigid, device-centric model to a flexible, workload-aware approach:</p>
<p><strong>Traditional Approach:</strong></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">limits</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Get entire GPU, no customization</span><br></span></code></pre></div></div>
<p><strong>DRA Approach:</strong></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">source</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template  </span><span class="token comment" style="color:#999988;font-style:italic"># Detailed requirements</span><br></span></code></pre></div></div>
<p><em>See examples section below for ResourceClaimTemplate configurations.</em></p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Namespace Requirement</div><div class="admonitionContent_BuS1"><p><strong>Critical:</strong> ResourceClaims must exist in the same namespace as the Pods that reference them. Cross-namespace resource claims are not supported.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-dra-innovations">Key DRA Innovations<a href="#key-dra-innovations" class="hash-link" aria-label="Direct link to Key DRA Innovations" title="Direct link to Key DRA Innovations">‚Äã</a></h3>
<div class="dra-innovations-grid"><div class="innovation-card innovation-card--primary"><div class="innovation-card__header"><div class="innovation-card__icon">üéØ</div><h4>Fine-grained Resource Control</h4></div><div class="innovation-card__content"><ul class="innovation-card__features"><li>Request specific GPU memory amounts (e.g., 16Gi out of 80Gi available)</li><li>Specify compute requirements independent of memory needs</li><li>Define topology constraints for multi-GPU workloads</li></ul><div class="innovation-card__note"><p><strong>Note:</strong> ResourceClaims and Pods must be in the same namespace</p></div></div></div><div class="innovation-card innovation-card--secondary"><div class="innovation-card__header"><div class="innovation-card__icon">üîÑ</div><h4>Per-Workload Sharing Strategies</h4></div><div class="innovation-card__content"><div class="strategy-grid"><div class="strategy-item"><p><strong>MPS</strong> - Concurrent small workloads with memory isolation</p></div><div class="strategy-item"><p><strong>Time-slicing</strong> - Workloads with different peak usage patterns</p></div><div class="strategy-item"><p><strong>MIG</strong> - Hardware-level isolation in multi-tenant environments</p></div><div class="strategy-item"><p><strong>Exclusive</strong> - Performance-critical training jobs</p></div></div></div></div><div class="innovation-card innovation-card--success"><div class="innovation-card__header"><div class="innovation-card__icon">üåê</div><h4>Topology-Aware Scheduling</h4></div><div class="innovation-card__content"><ul class="innovation-card__features"><li>Understands <a href="https://www.nvidia.com/en-us/data-center/nvlink/">NVLink</a> connections between GPUs</li><li>Leverages <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html">IMEX</a> for <a href="https://aws.amazon.com/ec2/instance-types/p6/">Amazon EC2 P6e-GB200 UltraServer</a> clusters</li><li>Optimizes placement for distributed training workloads</li></ul></div></div><div class="innovation-card innovation-card--warning"><div class="innovation-card__header"><div class="innovation-card__icon">üöÄ</div><h4>Future-Proof Architecture</h4></div><div class="innovation-card__content"><ul class="innovation-card__features"><li>Required for next-generation systems like <a href="https://aws.amazon.com/ec2/instance-types/p6/">Amazon EC2 P6e-GB200 UltraServers</a></li><li>Enables advanced features like Multi-Node <a href="https://www.nvidia.com/en-us/data-center/nvlink/">NVLink</a></li><li>Supports emerging GPU architectures and sharing technologies</li></ul></div></div></div>
<style>
.dra-innovations-grid {
display: grid;
grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
gap: 1.5rem;
margin: 2rem 0;
}

.innovation-card {
background: var(--ifm-background-surface-color);
border: 1px solid var(--ifm-color-emphasis-300);
border-radius: 12px;
padding: 1.5rem;
transition: all 0.3s ease;
box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
}

.innovation-card:hover {
transform: translateY(-4px);
box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
}

.innovation-card--primary {
border-left: 4px solid var(--ifm-color-primary);
}

.innovation-card--secondary {
border-left: 4px solid var(--ifm-color-secondary);
}

.innovation-card--success {
border-left: 4px solid var(--ifm-color-success);
}

.innovation-card--warning {
border-left: 4px solid var(--ifm-color-warning);
}

.innovation-card__header {
display: flex;
align-items: center;
margin-bottom: 1rem;
}

.innovation-card__icon {
font-size: 2rem;
margin-right: 0.75rem;
}

.innovation-card__header h4 {
margin: 0;
font-size: 1.25rem;
font-weight: 600;
}

.innovation-card__content {
color: var(--ifm-color-content-secondary);
}

.innovation-card__features {
margin: 0;
padding-left: 1rem;
}

.innovation-card__features li {
margin-bottom: 0.5rem;
}

.innovation-card__note {
background: var(--ifm-color-warning-contrast-background);
border: 1px solid var(--ifm-color-warning-contrast-border);
border-radius: 6px;
padding: 0.75rem;
margin-top: 1rem;
font-size: 0.875rem;
}

.strategy-grid {
display: grid;
grid-template-columns: 1fr 1fr;
gap: 0.75rem;
}

.strategy-item {
background: var(--ifm-color-emphasis-100);
padding: 0.75rem;
border-radius: 6px;
font-size: 0.875rem;
border-left: 3px solid var(--ifm-color-secondary);
}

@media (max-width: 768px) {
.dra-innovations-grid {
  grid-template-columns: 1fr;
}

.strategy-grid {
  grid-template-columns: 1fr;
}
}
</style>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-imex-computedomains-and-amazon-ec2-p6e-gb200-multi-node-scheduling">Understanding IMEX, ComputeDomains, and Amazon EC2 P6e-GB200 Multi-Node Scheduling<a href="#understanding-imex-computedomains-and-amazon-ec2-p6e-gb200-multi-node-scheduling" class="hash-link" aria-label="Direct link to Understanding IMEX, ComputeDomains, and Amazon EC2 P6e-GB200 Multi-Node Scheduling" title="Direct link to Understanding IMEX, ComputeDomains, and Amazon EC2 P6e-GB200 Multi-Node Scheduling">‚Äã</a></h3>
<p><strong><a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a> (NVIDIA Internode Memory Exchange/Management Service)</strong> is NVIDIA&#x27;s orchestration service for GPU memory sharing across <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> multi-node deployments. In <a href="https://aws.amazon.com/ec2/instance-types/p6/" target="_blank" rel="noopener noreferrer">Amazon EC2 P6e-GB200 UltraServer</a> configurations, IMEX coordinates memory export and import operations between nodes, enabling direct GPU-to-GPU memory access across multiple compute nodes for massive AI model training with billions of parameters.</p>
<p><strong>ComputeDomains</strong> represent logical groupings of interconnected GPUs that can communicate efficiently through high-bandwidth connections like <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> or <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a>. DRA uses ComputeDomains to understand GPU topology and ensure workloads requiring multi-GPU coordination are scheduled on appropriately connected hardware.</p>
<p><strong>Amazon EC2 P6e-GB200 Multi-Node Scheduling</strong> leverages DRA&#x27;s topology awareness to coordinate workloads across multiple superchip nodes. Traditional GPU scheduling cannot understand these complex interconnect relationships, making DRA essential for optimal placement of distributed training jobs on <a href="https://aws.amazon.com/ec2/instance-types/p6/" target="_blank" rel="noopener noreferrer">Amazon EC2 P6e-GB200 UltraServer</a> systems where proper GPU topology selection directly impacts training performance.</p>
<p>For detailed configuration examples and implementation guidance, see the <a href="https://docs.aws.amazon.com/eks/latest/best-practices/aiml-compute.html#aiml-dra" target="_blank" rel="noopener noreferrer">AWS EKS AI/ML Best Practices documentation</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="implementation-considerations-for-eks">Implementation Considerations for EKS<a href="#implementation-considerations-for-eks" class="hash-link" aria-label="Direct link to Implementation Considerations for EKS" title="Direct link to Implementation Considerations for EKS">‚Äã</a></h2>
<p>Now that we understand DRA&#x27;s capabilities and advanced features like IMEX and ComputeDomains, let&#x27;s explore the practical considerations for implementing DRA on Amazon EKS. The following sections address key decisions around node provisioning, migration strategies, and EKS-specific configurations that will determine your DRA deployment success.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="managed-node-groups-vs-karpenter-for-p-series-gpu-instances-and-dra">Managed Node Groups vs Karpenter for P-Series GPU Instances and DRA<a href="#managed-node-groups-vs-karpenter-for-p-series-gpu-instances-and-dra" class="hash-link" aria-label="Direct link to Managed Node Groups vs Karpenter for P-Series GPU Instances and DRA" title="Direct link to Managed Node Groups vs Karpenter for P-Series GPU Instances and DRA">‚Äã</a></h3>
<p>The choice between node provisioning methods for DRA isn&#x27;t just about technical compatibility. It&#x27;s fundamentally about how GPU capacity is purchased and utilized in enterprise AI workloads. <strong>Managed and Self-Managed Node Groups are currently the recommended approach for DRA because they align with the economics and operational patterns of high-end GPU instances.</strong></p>
<p>Here&#x27;s why: The majority of large GPU instances (<a href="https://aws.amazon.com/ec2/instance-types/p4/" target="_blank" rel="noopener noreferrer">P4d</a> (A100), <a href="https://aws.amazon.com/ec2/instance-types/p5/" target="_blank" rel="noopener noreferrer">P5</a> (H100), <a href="https://aws.amazon.com/ec2/instance-types/p6/" target="_blank" rel="noopener noreferrer">P6 with B200</a>, and <a href="https://www.nvidia.com/en-us/data-center/gb200-nvl72/" target="_blank" rel="noopener noreferrer">P6e with GB200</a>) are primarily available through AWS Capacity Block Reservations rather than on-demand pricing. <strong>When organizations purchase Capacity Blocks, they commit to paying for every second of GPU time until the reservation expires, regardless of whether the GPUs are actively utilized.</strong> This creates a fundamental mismatch with Karpenter&#x27;s core value proposition of dynamic scaling based on workload demand. Spinning nodes down during low-demand periods doesn&#x27;t save money. It actually wastes the reserved capacity you&#x27;re already paying for.</p>
<p>Additionally, <strong>Karpenter doesn&#x27;t yet support DRA scheduling</strong> (<a href="https://github.com/kubernetes-sigs/karpenter/issues/1231" target="_blank" rel="noopener noreferrer">Issue #1231</a> tracks active development), making it incompatible with production DRA workloads. While Karpenter excels at cost optimization through dynamic scaling for general compute workloads, <strong>Capacity Block reservations require an &quot;always-on&quot; utilization strategy to maximize ROI</strong>: exactly what Managed Node Groups provide with their static capacity model.</p>
<p><strong>The future picture is more optimistic:</strong> Karpenter&#x27;s roadmap includes static node features that would make it suitable for Capacity Block scenarios. The community is actively working on <a href="https://github.com/kubernetes-sigs/karpenter/issues/749" target="_blank" rel="noopener noreferrer">manual node provisioning without workloads</a> and static provisioning capabilities through RFCs like <a href="https://github.com/kubernetes-sigs/karpenter/pull/2309" target="_blank" rel="noopener noreferrer">static provisioning</a> and <a href="https://github.com/kubernetes-sigs/karpenter/pull/2397" target="_blank" rel="noopener noreferrer">manual node provisioning</a>. Once DRA support is added alongside these static provisioning capabilities, Karpenter could become the preferred choice for DRA workloads with Capacity Block ML reserved instances. Until then, <strong>Managed Node Groups with EKS-optimized AMIs (which come with pre-installed NVIDIA drivers) provide the most reliable foundation for DRA implementations.</strong></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dra-and-traditional-gpu-allocation-coexistence">DRA and Traditional GPU Allocation Coexistence<a href="#dra-and-traditional-gpu-allocation-coexistence" class="hash-link" aria-label="Direct link to DRA and Traditional GPU Allocation Coexistence" title="Direct link to DRA and Traditional GPU Allocation Coexistence">‚Äã</a></h3>
<p><strong>Yes, but with careful configuration to avoid conflicts.</strong> DRA and traditional GPU allocation can coexist on the same cluster, but this requires thoughtful setup to prevent resource double-allocation issues. NVIDIA&#x27;s DRA driver is designed as an additional component alongside the GPU Operator, with selective enablement to avoid conflicts.</p>
<p><strong>The recommended approach for gradual migration:</strong> Configure the NVIDIA DRA driver to enable only specific subsystems initially. For example, you can set <code>resources.gpus.enabled=false</code> to use traditional device plugins for GPU allocation while enabling DRA&#x27;s ComputeDomain subsystem for Multi-Node NVLink capabilities. This allows teams to gain operational experience with DRA&#x27;s advanced features without risking established GPU allocation workflows.</p>
<p><strong>Key considerations for coexistence:</strong></p>
<ul>
<li><strong>Avoid same-device conflicts</strong>: DRA and device plugins should not manage the same GPU devices simultaneously</li>
<li><strong>Selective component enablement</strong>: Use NVIDIA DRA driver&#x27;s modular design to enable features gradually</li>
<li><strong>Node selector management</strong>: Configure node selectors carefully to prevent resource allocation conflicts</li>
<li><strong>Technology Preview status</strong>: GPU allocation and sharing features are in Technology Preview (check <a href="https://github.com/NVIDIA/k8s-dra-driver-gpu" target="_blank" rel="noopener noreferrer">NVIDIA DRA Driver GitHub</a> for updates)</li>
</ul>
<p><strong>For migration planning,</strong> start with DRA&#x27;s production-ready features like ComputeDomains for Multi-Node <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a>, while keeping traditional device plugins for core GPU allocation. Once DRA&#x27;s GPU allocation reaches full support, gradually migrate workloads starting with development and inference services before moving mission-critical training jobs. <strong>NVIDIA and the Kubernetes community have designed DRA as the eventual replacement for device plugins</strong>, but the transition requires careful orchestration to maintain cluster stability.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="visual-comparison-traditional-vs-dra">Visual Comparison: Traditional vs DRA<a href="#visual-comparison-traditional-vs-dra" class="hash-link" aria-label="Direct link to Visual Comparison: Traditional vs DRA" title="Direct link to Visual Comparison: Traditional vs DRA">‚Äã</a></h3>
<p>The diagram below illustrates how DRA fundamentally changes the scheduling flow:</p>
<ul>
<li><strong>Traditional Model</strong>: The pod directly requests an entire GPU via the node resource model. Scheduling and allocation are static, with no room for partial usage or workload intent.</li>
<li><strong>DRA Model</strong>: Pods express intent via templates; claims are dynamically generated and resolved with the help of a DRA-aware scheduler and device driver. Multiple workloads can share GPUs safely and efficiently, maximizing utilization.</li>
</ul>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="technical-capabilities-comparison">Technical Capabilities Comparison<a href="#technical-capabilities-comparison" class="hash-link" aria-label="Direct link to Technical Capabilities Comparison" title="Direct link to Technical Capabilities Comparison">‚Äã</a></h3>
<div class="capabilityComparison_G6Wg"><div class="comparisonHeader_puLN"><div>Capability</div><div>üî¥ Traditional Device Plugin</div><div>üü¢ Dynamic Resource Allocation (DRA)</div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>Resource Request Model</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusNone_kihA">‚ùå</span><div class="capabilityDesc_xW7N">Simple integers<div><code>nvidia.com/gpu: 1</code></div></div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">‚úÖ</span><div class="capabilityDesc_xW7N">Structured claims via<div><code>ResourceClaimTemplate</code></div></div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>GPU Memory Specification</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusNone_kihA">‚ùå</span><div class="capabilityDesc_xW7N">All-or-nothing allocation</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">‚úÖ</span><div class="capabilityDesc_xW7N">Memory-based constraints and selectors</div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>Sharing Configuration</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusLimited_tWm3">‚ö†Ô∏è</span><div class="capabilityDesc_xW7N">Static cluster-wide ConfigMaps</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">‚úÖ</span><div class="capabilityDesc_xW7N">Per-workload sharing strategies</div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>Multi-GPU Topology Awareness</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusNone_kihA">‚ùå</span><div class="capabilityDesc_xW7N">No topology coordination</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">‚úÖ</span><div class="capabilityDesc_xW7N">DeviceClass selectors for NVLink, IMEX</div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>Runtime Reconfiguration</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusNone_kihA">‚ùå</span><div class="capabilityDesc_xW7N">Requires pod deletion and redeployment</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">‚úÖ</span><div class="capabilityDesc_xW7N">Dynamic reallocation without restarts</div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>MIG Support</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusLimited_tWm3">‚ö†Ô∏è</span><div class="capabilityDesc_xW7N">Limited - static partitions, manual setup</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">‚úÖ</span><div class="capabilityDesc_xW7N">Full MIG profiles via dynamic claims</div></div></div></div>
<div class="sectionDivider_z07Q"><div class="dividerLine_oAnl"></div><div class="dividerIcon_Soi9">‚öôÔ∏è</div><div class="dividerLine_oAnl"></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-dra-actually-works-the-complete-technical-flow">How DRA Actually Works: The Complete Technical Flow<a href="#how-dra-actually-works-the-complete-technical-flow" class="hash-link" aria-label="Direct link to How DRA Actually Works: The Complete Technical Flow" title="Direct link to How DRA Actually Works: The Complete Technical Flow">‚Äã</a></h2>
<p>Dynamic Resource Allocation (DRA) extends Kubernetes scheduling with a modular, pluggable mechanism for handling GPU and other device resources. Rather than allocating integer units of opaque hardware, DRA introduces <code>ResourceClaims</code>, <code>ResourceClaimTemplates</code>, <code>DeviceClasses</code>, and <code>ResourceSlices</code> to express, match, and provision device requirements at runtime.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-by-step-dra-workflow">Step-by-step DRA Workflow<a href="#step-by-step-dra-workflow" class="hash-link" aria-label="Direct link to Step-by-step DRA Workflow" title="Direct link to Step-by-step DRA Workflow">‚Äã</a></h3>
<p>DRA fundamentally changes how Kubernetes manages GPU resources through sophisticated orchestration:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-resource-discovery-and-advertisement">1. Resource Discovery and Advertisement<a href="#1-resource-discovery-and-advertisement" class="hash-link" aria-label="Direct link to 1. Resource Discovery and Advertisement" title="Direct link to 1. Resource Discovery and Advertisement">‚Äã</a></h4>
<p>When NVIDIA DRA driver starts, it discovers available GPUs on each node and creates <strong>ResourceSlices</strong> that advertise device capabilities to the Kubernetes API server.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-deviceclass-registration">2. DeviceClass Registration<a href="#2-deviceclass-registration" class="hash-link" aria-label="Direct link to 2. DeviceClass Registration" title="Direct link to 2. DeviceClass Registration">‚Äã</a></h4>
<p>The driver registers one or more <code>DeviceClass</code> objects to logically group GPU resources:</p>
<ul>
<li><code>gpu.nvidia.com</code>: Standard GPU resources</li>
<li><code>mig.nvidia.com</code>: Multi-Instance GPU partitions</li>
<li><code>compute-domain.nvidia.com</code>: Cross-node GPU coordination</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-resource-claim-creation">3. Resource Claim Creation<a href="#3-resource-claim-creation" class="hash-link" aria-label="Direct link to 3. Resource Claim Creation" title="Direct link to 3. Resource Claim Creation">‚Äã</a></h4>
<p><strong>ResourceClaimTemplates</strong> generate individual <strong>ResourceClaims</strong> for each pod, specifying:</p>
<ul>
<li>Specific GPU memory requirements</li>
<li>Sharing strategy (MPS, time-slicing, exclusive)</li>
<li>Driver versions and compute capabilities</li>
<li>Topology constraints for multi-GPU workloads</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-intelligent-scheduling">4. Intelligent Scheduling<a href="#4-intelligent-scheduling" class="hash-link" aria-label="Direct link to 4. Intelligent Scheduling" title="Direct link to 4. Intelligent Scheduling">‚Äã</a></h4>
<p>The DRA-aware scheduler evaluates pending <code>ResourceClaims</code> and queries available <code>ResourceSlices</code> across nodes:</p>
<ul>
<li>Matches device properties and constraints using CEL expressions</li>
<li>Ensures sharing strategy compatibility with other running pods</li>
<li>Selects optimal nodes considering topology, availability, and policy</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="5-dynamic-allocation">5. Dynamic Allocation<a href="#5-dynamic-allocation" class="hash-link" aria-label="Direct link to 5. Dynamic Allocation" title="Direct link to 5. Dynamic Allocation">‚Äã</a></h4>
<p>On the selected node, the DRA driver:</p>
<ul>
<li>Sets up device access for the container (e.g., mounts MIG instance or configures MPS)</li>
<li>Allocates shared vs. exclusive access as per claim configuration</li>
<li>Isolates GPU slices securely between concurrent workloads</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploying-the-solution">Deploying the Solution<a href="#deploying-the-solution" class="hash-link" aria-label="Direct link to Deploying the Solution" title="Direct link to Deploying the Solution">‚Äã</a></h2>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><strong>üëá In this example, you will provision JARK Cluster on Amazon EKS with DRA support</strong></summary><div><div class="collapsibleContent_i85q"><div class="progressSteps_j3Cn"><div class="step_wyHJ stepCurrent_baCR"><div class="stepNumber_JvFJ">1</div><div class="stepContent_kF1B"><h4>Prerequisites</h4><p>Install required tools and dependencies</p></div></div><div class="step_wyHJ"><div class="stepNumber_JvFJ">2</div><div class="stepContent_kF1B"><h4>Deploy</h4><p>Configure and run JARK stack installation</p></div></div><div class="step_wyHJ"><div class="stepNumber_JvFJ">3</div><div class="stepContent_kF1B"><h4>Verify</h4><p>Test your DRA deployment and validate functionality</p></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites">‚Äã</a></h3><p>Ensure that you have installed the following tools on your machine:</p><ul>
<li><strong><a href="https://aws.amazon.com/cli/" target="_blank" rel="noopener noreferrer">AWS CLI</a></strong> - AWS Command Line Interface</li>
<li><strong>kubectl</strong> - Kubernetes command-line tool</li>
<li><strong>terraform</strong> - Infrastructure as Code tool</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="deploy">Deploy<a href="#deploy" class="hash-link" aria-label="Direct link to Deploy" title="Direct link to Deploy">‚Äã</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-clone-the-repository">1. Clone the repository:<a href="#1-clone-the-repository" class="hash-link" aria-label="Direct link to 1. Clone the repository:" title="Direct link to 1. Clone the repository:">‚Äã</a></h4><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Clone the repository</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/awslabs/ai-on-eks.git</span><br></span></code></pre></div></div><div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Authentication Profile</div><div class="admonitionContent_BuS1"><p>If you are using a profile for authentication, set your <code>export AWS_PROFILE=&quot;&lt;PROFILE_name&gt;&quot;</code> to the desired profile name</p></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-review-and-customize-configurations">2. Review and customize configurations:<a href="#2-review-and-customize-configurations" class="hash-link" aria-label="Direct link to 2. Review and customize configurations:" title="Direct link to 2. Review and customize configurations:">‚Äã</a></h4><ul>
<li>Check available addons in <code>infra/base/terraform/variables.tf</code></li>
<li>Modify addon settings in <code>infra/jark-stack/terraform/blueprint.tfvars</code> as needed</li>
<li>Update the AWS region in <code>blueprint.tfvars</code></li>
</ul><p><strong>Enable DRA Components:</strong></p><p>In the <a href="https://github.com/awslabs/ai-on-eks/blob/main/infra/jark-stack/terraform/blueprint.tfvars" target="_blank" rel="noopener noreferrer"><code>blueprint.tfvars</code></a> file, uncomment the following lines:</p><div class="language-hcl codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">blueprint.tfvars</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-hcl codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token property" style="color:#36acaa">enable_nvidia_dra_driver</span><span class="token plain">         </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token property" style="color:#36acaa">enable_nvidia_gpu_operator</span><span class="token plain">       </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">true</span></span><br></span></code></pre></div></div><div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Automated Setup</div><div class="admonitionContent_BuS1"><p>The NVIDIA GPU Operator includes all necessary components:</p><ul>
<li>NVIDIA Device Plugin</li>
<li>DCGM Exporter</li>
<li>MIG Manager</li>
<li>GPU Feature Discovery</li>
<li>Node Feature Discovery</li>
</ul><p>The NVIDIA DRA Driver is deployed as a separate Helm chart parallel to the GPU Operator.</p></div></div><div class="progressSteps_j3Cn"><div class="step_wyHJ stepCompleted_BhoT"><div class="stepNumber_JvFJ">1</div><div class="stepContent_kF1B"><h4>Prerequisites</h4><p>Install required tools and dependencies</p></div></div><div class="step_wyHJ stepCurrent_baCR"><div class="stepNumber_JvFJ">2</div><div class="stepContent_kF1B"><h4>Deploy</h4><p>Configure and run JARK stack installation</p></div></div><div class="step_wyHJ"><div class="stepNumber_JvFJ">3</div><div class="stepContent_kF1B"><h4>Verify</h4><p>Test your DRA deployment and validate functionality</p></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-navigate-to-the-deployment-directory-and-run-the-install-script">3. Navigate to the deployment directory and run the install script:<a href="#3-navigate-to-the-deployment-directory-and-run-the-install-script" class="hash-link" aria-label="Direct link to 3. Navigate to the deployment directory and run the install script:" title="Direct link to 3. Navigate to the deployment directory and run the install script:">‚Äã</a></h4><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Deploy JARK Stack with DRA</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/infra/jark-stack </span><span class="token operator" style="color:#393A34">&amp;&amp;</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> +x install.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./install.sh</span><br></span></code></pre></div></div><p>This script will automatically provision and configure the following components:</p><ul>
<li>Amazon EKS Cluster with DRA (Dynamic Resource Allocation) feature gates enabled.</li>
<li>Two GPU-managed node groups using Amazon Linux 2023 GPU AMIs:</li>
<li>G6 Node Group: Intended for testing MPS and time-slicing strategies.</li>
<li>P4d(e) Node Group: Intended for testing MIG-based GPU partitioning.</li>
</ul><blockquote>
<p>‚ö†Ô∏è Both node groups are initialized with zero nodes to avoid unnecessary cost.</p>
</blockquote><ul>
<li>To test MPS/time-slicing, manually update the <code>g6</code> node group‚Äôs <code>min_size</code> and <code>desired_size</code> via the EKS console.</li>
<li>To test MIG, you need at least one <code>p4d</code> or <code>p4de</code> instance, which requires a Capacity Block Reservation (CBR). Edit the file: <code>infra/base/terraform/eks.tf</code>. Set your actual <code>capacity_reservation_id</code> and change the <code>min_size</code> for the MIG node group to <code>1</code></li>
</ul><div class="progressSteps_j3Cn"><div class="step_wyHJ stepCompleted_BhoT"><div class="stepNumber_JvFJ">1</div><div class="stepContent_kF1B"><h4>Prerequisites</h4><p>Install required tools and dependencies</p></div></div><div class="step_wyHJ stepCompleted_BhoT"><div class="stepNumber_JvFJ">2</div><div class="stepContent_kF1B"><h4>Deploy</h4><p>Configure and run JARK stack installation</p></div></div><div class="step_wyHJ stepCurrent_baCR"><div class="stepNumber_JvFJ">3</div><div class="stepContent_kF1B"><h4>Verify</h4><p>Test your DRA deployment and validate functionality</p></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-verify-deployment">4. Verify Deployment<a href="#4-verify-deployment" class="hash-link" aria-label="Direct link to 4. Verify Deployment" title="Direct link to 4. Verify Deployment">‚Äã</a></h4><p>Follow these verification steps to ensure your DRA deployment is working correctly:</p><p><strong>Step 1: Configure kubectl access</strong></p><p>Update your local kubeconfig to access the Kubernetes cluster:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">aws eks update-kubeconfig </span><span class="token parameter variable" style="color:#36acaa">--name</span><span class="token plain"> jark-stack  </span><span class="token comment" style="color:#999988;font-style:italic"># Replace with your EKS cluster name</span><br></span></code></pre></div></div><p><strong>Step 2: Verify worker nodes</strong></p><p>First, let&#x27;s verify that worker nodes are running in the cluster:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get nodes</span><br></span></code></pre></div></div><p><strong>Expected output:</strong> You should see two x86 instances from the core node group, plus any GPU instances (g6, p4d, etc.) that you manually scaled up via the EKS console.</p><p><strong>Step 3: Verify DRA components</strong></p><p>Run this command to verify all deployments, including the NVIDIA GPU Operator and NVIDIA DRA Driver:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get deployments </span><span class="token parameter variable" style="color:#36acaa">-A</span><br></span></code></pre></div></div><p><strong>Expected output:</strong> All pods should be in <code>Running</code> state before proceeding to test the examples below.</p><p><strong>Instance compatibility for testing:</strong></p><ul>
<li><strong>Time-slicing and MPS</strong>: Any G5 or G6 instance</li>
<li><strong>MIG partitioning</strong>: P-series instances (P4d or higher)</li>
<li><strong>IMEX use cases</strong>: P6e-GB200 UltraServers</li>
</ul><p>Once all components are running, you can start testing the various DRA examples mentioned in the following sections.</p></div></div></details>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="component-architecture">Component Architecture<a href="#component-architecture" class="hash-link" aria-label="Direct link to Component Architecture" title="Direct link to Component Architecture">‚Äã</a></h3>
<!-- -->
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>NVIDIA Tools</div><div class="admonitionContent_BuS1"><p>The NVIDIA DRA Driver runs as an independent Helm chart parallel to the NVIDIA GPU Operator, not as part of it. Both components work together to provide comprehensive GPU management capabilities.</p></div></div>
<div class="sectionDivider_z07Q"><div class="dividerLine_oAnl"></div><div class="dividerIcon_Soi9">üé≤</div><div class="dividerLine_oAnl"></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gpu-sharing-strategies-technical-deep-dive">GPU Sharing Strategies: Technical Deep Dive<a href="#gpu-sharing-strategies-technical-deep-dive" class="hash-link" aria-label="Direct link to GPU Sharing Strategies: Technical Deep Dive" title="Direct link to GPU Sharing Strategies: Technical Deep Dive">‚Äã</a></h2>
<p>Understanding GPU sharing technologies is crucial for optimizing resource utilization. Each strategy provides different benefits and addresses specific use cases.</p>
<div class="tabs-container"><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">üíé Basic Allocation</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">‚åõ Time-Slicing</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">üåä Multi-Process Service (MPS)</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">üèóÔ∏è Multi-Instance GPU (MIG)</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-gpu-allocation">Basic GPU Allocation<a href="#basic-gpu-allocation" class="hash-link" aria-label="Direct link to Basic GPU Allocation" title="Direct link to Basic GPU Allocation">‚Äã</a></h3><p>Standard GPU allocation without sharing - each workload gets exclusive access to a complete GPU. This is the traditional model that provides maximum performance isolation.</p><p><strong>How to Deploy Basic Allocation:</strong></p><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">ResourceClaimTemplate</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Basic Pod</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">basic-gpu-claim-template.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Namespace</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">test1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">test1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> single</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">basic-gpu-pod.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">test1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ctr0</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ubuntu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">22.04</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;bash&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;-c&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;nvidia-smi -L; trap &#x27;exit 0&#x27; TERM; sleep 9999 &amp; wait&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu0</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu0</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> single</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">NodeGroupType</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g6</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mng</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;nvidia.com/gpu&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Exists&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;NoSchedule&quot;</span></span><br></span></code></pre></div></div></div></div></div><p><strong>Deploy the Example:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Deploy Basic GPU Allocation</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> basic-gpu-claim-template.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> basic-gpu-pod.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-test1 </span><span class="token parameter variable" style="color:#36acaa">-w</span><br></span></code></pre></div></div><p><strong>Best For:</strong></p><ul>
<li>Large model training requiring full GPU resources</li>
<li>Workloads that fully utilize GPU compute and memory</li>
<li>Applications requiring maximum performance isolation</li>
<li>Legacy applications not designed for GPU sharing</li>
</ul></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-time-slicing">What is Time-Slicing?<a href="#what-is-time-slicing" class="hash-link" aria-label="Direct link to What is Time-Slicing?" title="Direct link to What is Time-Slicing?">‚Äã</a></h3><p>Time-slicing is a GPU sharing mechanism where multiple workloads take turns using the GPU, with each getting exclusive access during their allocated time slice. This approach is similar to CPU time-sharing but applied to GPU resources.</p><p><strong>Technical Implementation:</strong></p><ul>
<li>The GPU scheduler allocates specific time windows (typically 1-10ms) to each workload</li>
<li>During a workload&#x27;s time slice, it has complete access to GPU compute and memory</li>
<li>Context switching occurs between time slices, saving and restoring GPU state</li>
<li>No memory isolation between workloads - they share the same GPU memory space</li>
</ul><p><strong>Key Characteristics:</strong></p><ul>
<li><strong>Temporal Isolation</strong>: Workloads are isolated in time but not in memory</li>
<li><strong>Full GPU Access</strong>: Each workload gets complete GPU resources during its slice</li>
<li><strong>Context Switching Overhead</strong>: Small performance penalty for switching between workloads</li>
<li><strong>Flexible Allocation</strong>: Time slice duration can be adjusted based on workload requirements</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-deploy-time-slicing-with-dra">How to Deploy Time-Slicing with DRA<a href="#how-to-deploy-time-slicing-with-dra" class="hash-link" aria-label="Direct link to How to Deploy Time-Slicing with DRA" title="Direct link to How to Deploy Time-Slicing with DRA">‚Äã</a></h3><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">ResourceClaimTemplate</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pod Configuration</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">timeslicing-claim-template.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Namespace</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;shared-gpu&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">opaque</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">driver</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.nvidia.com/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> GpuConfig</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">sharing</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">              </span><span class="token key atrule" style="color:#00a4db">strategy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> TimeSlicing</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">timeslicing-pod.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token comment" style="color:#999988;font-style:italic"># ConfigMap containing Python scripts for timeslicing pods</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ConfigMap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">data</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">inference-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;=== POD 1 STARTING ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;GPU available: {torch.cuda.is_available()}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;GPU count: {torch.cuda.device_count()}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    if torch.cuda.is_available():</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(f&quot;Current GPU: {torch.cuda.get_device_name(device)}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(f&quot;GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        # Simulate inference workload</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        for i in range(20):</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            x = torch.randn(1000, 1000).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            y = torch.mm(x, x.t())</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            print(f&quot;Pod 1 - Iteration {i+1} completed at {time.strftime(&#x27;%H:%M:%S&#x27;)}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            time.sleep(5)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    else:</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(&quot;No GPU available!&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        time.sleep(60)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">training-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;=== POD 2 STARTING ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;GPU available: {torch.cuda.is_available()}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;GPU count: {torch.cuda.device_count()}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    if torch.cuda.is_available():</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(f&quot;Current GPU: {torch.cuda.get_device_name(device)}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(f&quot;GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        # Simulate training workload with heavier compute</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        for i in range(15):</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            x = torch.randn(2000, 2000).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            y = torch.mm(x, x.t())</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            loss = torch.sum(y)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            print(f&quot;Pod 2 - Training step {i+1}, Loss: {loss.item():.2f} at {time.strftime(&#x27;%H:%M:%S&#x27;)}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            time.sleep(5)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    else:</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(&quot;No GPU available!&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        time.sleep(60)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 1 - Inference workload</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">inference</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/inference-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">NodeGroupType</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g6</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mng</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 2 - Training workload</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/training-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">NodeGroupType</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g6</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mng</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span></span><br></span></code></pre></div></div></div></div></div><p><strong>Deploy the Example:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Deploy Time-Slicing GPU Sharing</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> timeslicing-claim-template.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> timeslicing-pod.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu </span><span class="token parameter variable" style="color:#36acaa">-w</span><br></span></code></pre></div></div><p><strong>Best For:</strong></p><ul>
<li>Inference workloads with sporadic GPU usage</li>
<li>Development and testing environments</li>
<li>Workloads with different peak usage times</li>
<li>Applications that don&#x27;t require memory isolation</li>
</ul><div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Time-Slicing Limitations</div><div class="admonitionContent_BuS1"><p>No memory or fault isolation between workloads. One workload can affect others through memory exhaustion or GPU errors.</p></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-mps">What is MPS?<a href="#what-is-mps" class="hash-link" aria-label="Direct link to What is MPS?" title="Direct link to What is MPS?">‚Äã</a></h3><p>NVIDIA Multi-Process Service (MPS) is a GPU sharing technology that allows multiple CUDA applications to run concurrently on the same GPU by creating a daemon that manages GPU access and enables spatial sharing of GPU resources.</p><p><strong>Technical Implementation:</strong></p><ul>
<li>MPS daemon acts as a proxy between CUDA applications and the GPU driver</li>
<li>Each process gets dedicated GPU memory allocation</li>
<li>Compute kernels from different processes can execute simultaneously when resources allow</li>
<li>Memory isolation is maintained between processes</li>
<li>Hardware scheduling enables true parallel execution</li>
</ul><p><strong>Key Characteristics:</strong></p><ul>
<li><strong>Spatial Isolation</strong>: GPU compute units can be shared simultaneously</li>
<li><strong>Memory Isolation</strong>: Each process has dedicated memory space</li>
<li><strong>Concurrent Execution</strong>: Multiple kernels can run in parallel</li>
<li><strong>Lower Latency</strong>: Reduced context switching compared to time-slicing</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-deploy-mps-with-dra">How to Deploy MPS with DRA<a href="#how-to-deploy-mps-with-dra" class="hash-link" aria-label="Direct link to How to Deploy MPS with DRA" title="Direct link to How to Deploy MPS with DRA">‚Äã</a></h3><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">ResourceClaimTemplate</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Multi-Container Pod</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">mps-claim-template.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Namespace</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;shared-gpu&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">opaque</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">driver</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.nvidia.com/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> GpuConfig</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">sharing</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">              </span><span class="token key atrule" style="color:#00a4db">strategy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> MPS</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">mps-pod.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token comment" style="color:#999988;font-style:italic"># ConfigMap containing Python scripts for MPS pods</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ConfigMap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">data</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">inference-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== INFERENCE CONTAINER STARTING ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Current GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1024</span><span class="token important">**3:.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Create inference model</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(1000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 500)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(500</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 100)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Run inference</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        for i in range(1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">999999)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">with torch.no_grad()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                x = torch.randn(128</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 1000).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                result = torch.sum(output)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                print(f&quot;Inference Container PID </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Batch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">i</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Result</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">result.item()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> at </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">time.strftime(&#x27;%H</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">%M</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">%S&#x27;)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(2)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">else</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;No GPU available</span><span class="token tag" style="color:#00009f">!</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        time.sleep(60)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">training-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== TRAINING CONTAINER STARTING ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Current GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1024</span><span class="token important">**3:.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Create training model</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(2000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 1000)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(1000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 500)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(500</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        criterion = nn.MSELoss()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        optimizer = torch.optim.Adam(model.parameters()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> lr=0.001)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Run training</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        for epoch in range(1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">999999)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            x = torch.randn(64</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 2000).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            target = torch.randn(64</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.zero_grad()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss = criterion(output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> target)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss.backward()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.step()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            print(f&quot;Training Container PID </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Epoch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">epoch</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Loss</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">loss.item()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.4f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> at </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">time.strftime(&#x27;%H</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">%M</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">%S&#x27;)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(3)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">else</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;No GPU available</span><span class="token tag" style="color:#00009f">!</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        time.sleep(60)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Single Pod with Multiple Containers sharing GPU via MPS</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">multi</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">demo</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Container 1 - Inference workload</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/inference-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">request</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Container 2 - Training workload</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/training-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">request</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">NodeGroupType</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g6</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mng</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span></span><br></span></code></pre></div></div></div></div></div><p><strong>Deploy the Example:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Deploy MPS GPU Sharing</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> mps-claim-template.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> mps-pod.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mps-gpu </span><span class="token parameter variable" style="color:#36acaa">-w</span><br></span></code></pre></div></div><p><strong>Best For:</strong></p><ul>
<li>Multiple small inference workloads</li>
<li>Concurrent model serving scenarios</li>
<li>Workloads using less than 50% of GPU compute</li>
<li>Applications requiring memory isolation</li>
</ul><div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>MPS Performance Benefits</div><div class="admonitionContent_BuS1"><p>MPS eliminates context switching overhead and enables true parallelism. Ideal for workloads using less than 50% of GPU compute capacity.</p></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-mig">What is MIG?<a href="#what-is-mig" class="hash-link" aria-label="Direct link to What is MIG?" title="Direct link to What is MIG?">‚Äã</a></h3><p>Multi-Instance GPU (MIG) is a hardware-level GPU partitioning technology available on NVIDIA A100, H100, and newer GPUs that creates smaller, isolated GPU instances with dedicated compute units, memory, and memory bandwidth.</p><p><strong>Technical Implementation:</strong></p><ul>
<li>Hardware-level partitioning creates separate GPU instances</li>
<li>Each MIG instance has dedicated streaming multiprocessors (SMs)</li>
<li>Memory and memory bandwidth are physically partitioned</li>
<li>Complete fault isolation between instances</li>
<li>Independent scheduling and execution contexts</li>
</ul><p><strong>Key Characteristics:</strong></p><ul>
<li><strong>Hardware Isolation</strong>: Physical separation of compute and memory resources</li>
<li><strong>Fault Isolation</strong>: Issues in one instance don&#x27;t affect others</li>
<li><strong>Predictable Performance</strong>: Guaranteed resources for each instance</li>
<li><strong>Fixed Partitioning</strong>: Predefined MIG profiles (1g.5gb, 2g.10gb, etc.)</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-deploy-mig-with-dra">How to Deploy MIG with DRA<a href="#how-to-deploy-mig-with-dra" class="hash-link" aria-label="Direct link to How to Deploy MIG with DRA" title="Direct link to How to Deploy MIG with DRA">‚Äã</a></h3><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">ResourceClaimTemplate</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">MIG Pod</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">mig-claim-template.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Namespace</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Template for 3g.40gb MIG instance (Large training)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">selectors</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">cel</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">expression</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">              device.attributes[&#x27;gpu.nvidia.com&#x27;].profile == &#x27;3g.40gb&#x27;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Template for 2g.20gb MIG instance (Medium training)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">selectors</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">cel</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">expression</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">              device.attributes[&#x27;gpu.nvidia.com&#x27;].profile == &#x27;2g.20gb&#x27;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Template for 1g.10gb MIG instance (Small inference)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">selectors</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">cel</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">expression</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">              device.attributes[&#x27;gpu.nvidia.com&#x27;].profile == &#x27;1g.10gb&#x27;</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">mig-pod.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token comment" style="color:#999988;font-style:italic"># ConfigMap containing Python scripts for MIG pods</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ConfigMap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">data</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">large-training-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.optim as optim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== LARGE TRAINING POD (3g.40gb) ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Using GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Large model for 3g.40gb instance</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(2048</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 1024)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(1024</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 512)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 256)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        optimizer = optim.Adam(model.parameters())</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        criterion = nn.CrossEntropyLoss()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Model parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">sum(p.numel() for p in model.parameters())</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Training loop</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">for epoch in range(100)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic"># Large batch for 3g.40gb</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            x = torch.randn(256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 2048).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            y = torch.randint(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> (256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">)).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.zero_grad()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss = criterion(output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss.backward()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.step()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">if epoch % 10 == 0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                print(f&quot;Large Training </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> Epoch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">epoch</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Loss</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">loss.item()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.4f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.memory_allocated()/1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(3)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;Large training completed on 3g.40gb MIG instance&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">medium-training-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.optim as optim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== MEDIUM TRAINING POD (2g.20gb) ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Using GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Medium model for 2g.20gb instance</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(1024</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 512)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 256)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        optimizer = optim.Adam(model.parameters())</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        criterion = nn.CrossEntropyLoss()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Model parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">sum(p.numel() for p in model.parameters())</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Training loop</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">for epoch in range(100)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic"># Medium batch for 2g.20gb</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            x = torch.randn(128</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 1024).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            y = torch.randint(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> (128</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">)).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.zero_grad()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss = criterion(output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss.backward()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.step()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">if epoch % 10 == 0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                print(f&quot;Medium Training </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> Epoch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">epoch</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Loss</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">loss.item()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.4f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.memory_allocated()/1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(4)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;Medium training completed on 2g.20gb MIG instance&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">small-inference-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== SMALL INFERENCE POD (1g.10gb) ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Using GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Small model for 1g.10gb instance</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 256)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Model parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">sum(p.numel() for p in model.parameters())</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Inference loop</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">for i in range(200)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">with torch.no_grad()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                </span><span class="token comment" style="color:#999988;font-style:italic"># Small batch for 1g.10gb</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                x = torch.randn(32</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 512).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                prediction = torch.argmax(output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dim=1)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                </span><span class="token key atrule" style="color:#00a4db">if i % 20 == 0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                    print(f&quot;Small Inference </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> Batch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">i</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Predictions</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">prediction</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">.tolist()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.memory_allocated()/1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(2)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;Small inference completed on 1g.10gb MIG instance&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 1: Large training workload (3g.40gb)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">workload-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/large-training-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">node.kubernetes.io/instance-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> p4de.24xlarge</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 2: Medium training workload (2g.20gb) - can run on SAME GPU as Pod 1</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">workload-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/medium-training-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">node.kubernetes.io/instance-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> p4de.24xlarge</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 3: Small inference workload (1g.10gb) - can run on SAME GPU as Pod 1 &amp; 2</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">inference</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">workload-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> inference</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/small-inference-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">node.kubernetes.io/instance-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> p4de.24xlarge</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span></span><br></span></code></pre></div></div></div></div></div><p><strong>Deploy the Example:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Deploy MIG GPU Partitioning</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> mig-claim-template.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> mig-pod.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mig-gpu </span><span class="token parameter variable" style="color:#36acaa">-w</span><br></span></code></pre></div></div><p><strong>Best For:</strong></p><ul>
<li>Multi-tenant environments requiring strict isolation</li>
<li>Predictable performance requirements</li>
<li>Production workloads requiring guaranteed resources</li>
<li>Compliance scenarios requiring hardware-level isolation</li>
</ul><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>MIG Requirements</div><div class="admonitionContent_BuS1"><ul>
<li>Hardware-level partitioning creates isolated GPU instances</li>
<li>Each MIG instance has dedicated compute units and memory</li>
<li>Complete fault isolation between instances</li>
<li>Requires GPU Operator with MIG Manager for dynamic reconfiguration</li>
</ul></div></div></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="strategy-selection-guide">Strategy Selection Guide<a href="#strategy-selection-guide" class="hash-link" aria-label="Direct link to Strategy Selection Guide" title="Direct link to Strategy Selection Guide">‚Äã</a></h3><table><thead><tr><th>Workload Type</th><th>Recommended Strategy</th><th>Key Benefit</th></tr></thead><tbody><tr><td><strong>Small Inference Jobs</strong></td><td>Time-slicing or MPS</td><td>Higher GPU utilization</td></tr><tr><td><strong>Concurrent Small Models</strong></td><td>MPS</td><td>True parallelism</td></tr><tr><td><strong>Production Multi-tenant</strong></td><td>MIG</td><td>Hardware isolation</td></tr><tr><td><strong>Large Model Training</strong></td><td>Basic Allocation</td><td>Maximum performance</td></tr><tr><td><strong>Development/Testing</strong></td><td>Time-slicing</td><td>Flexibility and simplicity</td></tr></tbody></table></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cleanup">Cleanup<a href="#cleanup" class="hash-link" aria-label="Direct link to Cleanup" title="Direct link to Cleanup">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="removing-dra-components">Removing DRA Components<a href="#removing-dra-components" class="hash-link" aria-label="Direct link to Removing DRA Components" title="Direct link to Removing DRA Components">‚Äã</a></h3>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">1Ô∏è‚É£ Clean Up DRA Examples</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">2Ô∏è‚É£ JARK Stack Cleanup</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><p><strong>Remove all DRA example workloads:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Clean up DRA workloads</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token comment" style="color:#999988;font-style:italic"># Delete all pods first to ensure proper cleanup</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod inference-pod-1 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod training-pod-2 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod mps-workload </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mps-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod mig-workload </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mig-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod basic-gpu-pod </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-test1 --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Delete ResourceClaimTemplates</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaimtemplate timeslicing-gpu-template </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaimtemplate mps-gpu-template </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mps-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaimtemplate mig-gpu-template </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mig-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaimtemplate basic-gpu-template </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-test1 --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Delete any remaining ResourceClaims</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaims </span><span class="token parameter variable" style="color:#36acaa">--all</span><span class="token plain"> --all-namespaces --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Delete ConfigMaps (contain scripts)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete configmap timeslicing-scripts-configmap </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Finally delete namespaces</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete namespace timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete namespace mps-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete namespace mig-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete namespace gpu-test1 --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Verify cleanup</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl get resourceclaims --all-namespaces</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl get resourceclaimtemplates --all-namespaces</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p><strong>For JARK-deployed clusters, use the automated cleanup:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">JARK Stack Complete Cleanup</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Navigate to JARK directory</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/infra/jark-stack/terraform/_LOCAL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Run the cleanup script</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> +x cleanup.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./cleanup.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Alternative: Manual terraform destroy</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># terraform destroy -var-file=terraform/blueprint.tfvars -auto-approve</span><br></span></code></pre></div></div><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Complete Infrastructure Removal</div><div class="admonitionContent_BuS1"><p>This will remove the entire EKS cluster and all associated resources. Ensure you have backed up any important data before proceeding.</p></div></div></div></div></div>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><strong>üîß Troubleshooting Common Issues</strong></summary><div><div class="collapsibleContent_i85q"><div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">üîç Pods Stuck in Pending</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">‚ö†Ô∏è GPU Sharing Conflicts</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">üìä Performance Issues</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><p><strong>Issue:</strong> Pods with ResourceClaims stuck in Pending state</p><p><strong>Diagnosis:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Check ResourceClaim status</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get resourceclaims --all-namespaces </span><span class="token parameter variable" style="color:#36acaa">-o</span><span class="token plain"> wide</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Check DRA driver logs</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-operator </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">app</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">nvidia-dra-driver </span><span class="token parameter variable" style="color:#36acaa">--tail</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">100</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Verify DeviceClasses exist</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get deviceclasses</span><br></span></code></pre></div></div><p><strong>Resolution:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Restart DRA driver pods</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl delete pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-operator </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">app</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">nvidia-dra-driver</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Check node GPU availability</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl describe nodes </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">grep</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-A</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Allocatable&quot;</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p><strong>Issue:</strong> Incompatible sharing strategies on same GPU</p><p><strong>Diagnosis:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Check ResourceSlice allocation</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get resourceslices </span><span class="token parameter variable" style="color:#36acaa">-o</span><span class="token plain"> yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Verify current allocations</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get resourceclaims --all-namespaces </span><span class="token parameter variable" style="color:#36acaa">-o</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">jsonpath</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;{range .items[*]}{.metadata.namespace}/{.metadata.name}: {.status.allocation.deviceResults[*].device}{&quot;\n&quot;}{end}&#x27;</span><br></span></code></pre></div></div><p><strong>Resolution:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Remove conflicting ResourceClaims</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl delete resourceclaim </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">conflicting-claim</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">namespace</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Wait for resource cleanup</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl </span><span class="token function" style="color:#d73a49">wait</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">--for</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">delete resourceclaim </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">claim-name</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">namespace</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">--timeout</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">60s</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p><strong>Issue:</strong> Suboptimal GPU utilization or performance</p><p><strong>Monitoring:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Check GPU utilization</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl </span><span class="token builtin class-name">exec</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-it</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">gpu-pod</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">namespace</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> -- nvidia-smi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Monitor ResourceClaim allocation</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get events --field-selector </span><span class="token assign-left variable" style="color:#36acaa">reason</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">ResourceClaimAllocated --sort-by</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;.lastTimestamp&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Check sharing strategy effectiveness</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">workload-pod</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">namespace</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">grep</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-i</span><span class="token plain"> gpu</span><br></span></code></pre></div></div><p><strong>Optimization:</strong></p><ul>
<li>Review sharing strategy selection (MPS vs time-slicing vs exclusive)</li>
<li>Validate workload resource requirements match allocation</li>
<li>Consider MIG partitioning for predictable isolation</li>
</ul></div></div></div></div></div></details>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">‚Äã</a></h2>
<p>Dynamic Resource Allocation represents a fundamental shift from rigid GPU allocation to intelligent, workload-aware resource management. By leveraging structured ResourceClaims and vendor-specific drivers, DRA unlocks the GPU utilization rates necessary for cost-effective AI/ML operations at enterprise scale.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>üöÄ Ready to Transform Your GPU Infrastructure?</div><div class="admonitionContent_BuS1"><p>With the simplified JARK-based deployment approach, organizations can implement production-grade DRA capabilities in three steps, transforming their GPU infrastructure from a static resource pool into a dynamic, intelligent platform optimized for modern AI workloads.</p></div></div>
<p>The combination of EKS&#x27;s managed infrastructure, NVIDIA&#x27;s driver ecosystem, and Kubernetes&#x27; declarative model creates a powerful foundation for next-generation AI workloads - from small inference jobs to multi-node distributed training on GB200 superchips.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/resources/dynamic-resource-allocation.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/docs/resources/binpacking-custom-scheduler-eks"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Bin packing for Amazon EKS</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-on-eks/docs/resources/observability"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Observability</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#dra-advantages-over-traditional-gpu-scheduling" class="table-of-contents__link toc-highlight">DRA Advantages over Traditional GPU Scheduling</a></li><li><a href="#why-managedself-managed-node-groups-vs-karpenter-for-dra" class="table-of-contents__link toc-highlight">Why Managed/Self-Managed Node Groups vs Karpenter for DRA?</a></li><li><a href="#can-i-use-both-traditional-gpu-allocation-and-dra-together" class="table-of-contents__link toc-highlight">Can I Use Both Traditional GPU Allocation and DRA Together?</a></li><li><a href="#production-readiness" class="table-of-contents__link toc-highlight">Production Readiness</a></li><li><a href="#the-gpu-scheduling-challenge-in-kubernetes" class="table-of-contents__link toc-highlight">The GPU Scheduling Challenge in Kubernetes</a><ul><li><a href="#current-state-traditional-gpu-allocation" class="table-of-contents__link toc-highlight">Current State: Traditional GPU Allocation</a></li><li><a href="#the-gpu-utilization-crisis" class="table-of-contents__link toc-highlight">The GPU Utilization Crisis</a></li></ul></li><li><a href="#enter-dynamic-resource-allocation-dra" class="table-of-contents__link toc-highlight">Enter Dynamic Resource Allocation (DRA)</a><ul><li><a href="#what-dra-changes" class="table-of-contents__link toc-highlight">What DRA Changes</a></li><li><a href="#key-dra-innovations" class="table-of-contents__link toc-highlight">Key DRA Innovations</a></li><li><a href="#understanding-imex-computedomains-and-amazon-ec2-p6e-gb200-multi-node-scheduling" class="table-of-contents__link toc-highlight">Understanding IMEX, ComputeDomains, and Amazon EC2 P6e-GB200 Multi-Node Scheduling</a></li></ul></li><li><a href="#implementation-considerations-for-eks" class="table-of-contents__link toc-highlight">Implementation Considerations for EKS</a><ul><li><a href="#managed-node-groups-vs-karpenter-for-p-series-gpu-instances-and-dra" class="table-of-contents__link toc-highlight">Managed Node Groups vs Karpenter for P-Series GPU Instances and DRA</a></li><li><a href="#dra-and-traditional-gpu-allocation-coexistence" class="table-of-contents__link toc-highlight">DRA and Traditional GPU Allocation Coexistence</a></li><li><a href="#visual-comparison-traditional-vs-dra" class="table-of-contents__link toc-highlight">Visual Comparison: Traditional vs DRA</a></li><li><a href="#technical-capabilities-comparison" class="table-of-contents__link toc-highlight">Technical Capabilities Comparison</a></li></ul></li><li><a href="#how-dra-actually-works-the-complete-technical-flow" class="table-of-contents__link toc-highlight">How DRA Actually Works: The Complete Technical Flow</a><ul><li><a href="#step-by-step-dra-workflow" class="table-of-contents__link toc-highlight">Step-by-step DRA Workflow</a></li></ul></li><li><a href="#deploying-the-solution" class="table-of-contents__link toc-highlight">Deploying the Solution</a><ul><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#deploy" class="table-of-contents__link toc-highlight">Deploy</a></li><li><a href="#component-architecture" class="table-of-contents__link toc-highlight">Component Architecture</a></li></ul></li><li><a href="#gpu-sharing-strategies-technical-deep-dive" class="table-of-contents__link toc-highlight">GPU Sharing Strategies: Technical Deep Dive</a><ul><li><a href="#basic-gpu-allocation" class="table-of-contents__link toc-highlight">Basic GPU Allocation</a></li><li><a href="#what-is-time-slicing" class="table-of-contents__link toc-highlight">What is Time-Slicing?</a></li><li><a href="#how-to-deploy-time-slicing-with-dra" class="table-of-contents__link toc-highlight">How to Deploy Time-Slicing with DRA</a></li><li><a href="#what-is-mps" class="table-of-contents__link toc-highlight">What is MPS?</a></li><li><a href="#how-to-deploy-mps-with-dra" class="table-of-contents__link toc-highlight">How to Deploy MPS with DRA</a></li><li><a href="#what-is-mig" class="table-of-contents__link toc-highlight">What is MIG?</a></li><li><a href="#how-to-deploy-mig-with-dra" class="table-of-contents__link toc-highlight">How to Deploy MIG with DRA</a></li><li><a href="#strategy-selection-guide" class="table-of-contents__link toc-highlight">Strategy Selection Guide</a></li></ul></li><li><a href="#cleanup" class="table-of-contents__link toc-highlight">Cleanup</a><ul><li><a href="#removing-dra-components" class="table-of-contents__link toc-highlight">Removing DRA Components</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ‚ù§Ô∏è at AWS  <br> ¬© 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>